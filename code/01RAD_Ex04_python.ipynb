{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francji1/01RAD/blob/main/code/01RAD_Ex04_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2q9hM8s44zX"
      },
      "source": [
        "\n",
        "# 01RAD Exercise 04\n",
        "\n",
        "- Residual diagnostics\n",
        "- Post-hoc analysis checks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaUjhI6c5XSm"
      },
      "source": [
        "$\\operatorname{Var}(\\hat{y}_i) = \\sigma^2 \\cdot \\mathbf{x}_i^\\top (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{x}_i$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dEl6naw6p4h"
      },
      "source": [
        "\n",
        "# Projection Hat Matrix $\\mathbf{H}$ and Matrix $\\mathbf{M}$\n",
        "\n",
        "## $\\mathbf{H}$: Hat Matrix\n",
        "\n",
        "$$\n",
        "\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top\n",
        "$$\n",
        "\n",
        "- Projects the observation vector $\\mathbf{Y}$ onto the column space generated by $\\mathbf{X}$.\n",
        "- \"Puts a hat\" on $\\mathbf{y}$, because $\\hat{\\mathbf{Y}} = \\mathbf{H} \\mathbf{Y}$.\n",
        "- In code: `hat_Y = H @ Y`.\n",
        "\n",
        "**Properties**\n",
        "\n",
        "- **Symmetry and idempotency**: $\\mathbf{H} = \\mathbf{H}^\\top$ and $\\mathbf{H}^2 = \\mathbf{H}$.\n",
        "- **Trace (degrees of freedom)**: $\\operatorname{tr}(\\mathbf{H}) = p$.\n",
        "- **Diagonal elements ($h_{ii}$) are leverage values**, quantifying how much each observation influences its own fitted value.\n",
        "\n",
        "## $\\mathbf{M}$ Matrix\n",
        "\n",
        "$$\n",
        "\\mathbf{M} = \\mathbf{I} - \\mathbf{H}\n",
        "$$\n",
        "\n",
        "- Complement of the hat matrix.\n",
        "- Projects onto the orthogonal complement of the column space of $\\mathbf{X}$.\n",
        "- Residual vector: $\\hat{\\mathbf{e}} = \\mathbf{M} \\mathbf{Y}$.\n",
        "\n",
        "**Properties**\n",
        "\n",
        "- **Symmetry and idempotency**: $\\mathbf{M} = \\mathbf{M}^\\top$ and $\\mathbf{M}^2 = \\mathbf{M}$.\n",
        "- **Orthogonality with $\\mathbf{H}$**: $\\mathbf{H}\\mathbf{M} = \\mathbf{0}$ and $\\mathbf{M}\\mathbf{H} = \\mathbf{0}$.\n",
        "- **Trace (residual degrees of freedom)**: $\\operatorname{tr}(\\mathbf{M}) = n - p$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avwj9HlrEVqa"
      },
      "source": [
        "\n",
        "## Questions\n",
        "\n",
        "- If $\\mathbf{X}$ has $n$ rows and $p$ linearly independent columns, what is the dimension of the original vector space on which $\\mathbf{H}$ and $\\mathbf{M}$ operate?\n",
        "- What is the dimension (rank) of the column space $\\operatorname{Col}(\\mathbf{X})$?\n",
        "- What is the dimension of $\\operatorname{Nul}(\\mathbf{X}^\\top)$, the orthogonal complement of $\\operatorname{Col}(\\mathbf{X})$, and what do we call this space?\n",
        "- Is the decomposition $\\mathbb{R}^n = \\operatorname{Col}(\\mathbf{X}) \\oplus \\operatorname{Nul}(\\mathbf{X}^T)$ correct?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdt65aLq5Wz7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09WuBHLzAqUB"
      },
      "source": [
        "\n",
        "### Types of residuals in linear regression\n",
        "\n",
        "$$\n",
        "Y_i = X_i \\beta + e_i, \\quad e_i \\sim \\mathcal{N}(0, \\sigma^2)\n",
        "$$\n",
        "\n",
        "Residuals measure the difference between observed and predicted values.\n",
        "\n",
        "#### 1. Raw residuals\n",
        "$$\n",
        "\\hat{e}_i = Y_i - \\hat{Y}_i\n",
        "$$\n",
        "\n",
        "#### 2. Standardized residuals (known $\\sigma$)\n",
        "Raw residuals scaled by their standard deviation when $\\sigma$ is known:\n",
        "$$\n",
        "\\hat{Z}_i = \\frac{\\hat{e}_i}{\\sigma \\sqrt{1 - h_{ii}}}\n",
        "$$\n",
        "Question: how is the variance of $\\hat{e}_i$ derived from $\\sigma^2$ and $h_{ii}$?\n",
        "\n",
        "#### 3. Internally studentized residuals (unknown $\\sigma$)\n",
        "Adjust raw residuals using the OLS variance estimate $s^2 = \\frac{1}{n - p} \\sum_{j=1}^n \\hat{e}_j^2$:\n",
        "$$\n",
        "\\hat{r}_i = \\frac{\\hat{e}_i}{s \\sqrt{1 - h_{ii}}}\n",
        "$$\n",
        "These residuals account for leverage but still use the variance estimate computed from all observations.\n",
        "\n",
        "#### 4. Externally studentized residuals\n",
        "Residuals scaled by their variance estimate excluding the ${i}$-th case:\n",
        "$$\n",
        "\\hat{r}_{(-i)} = \\frac{\\hat{e}}{s_{(-i)} \\sqrt{1 - h_{ii}}}, \\quad s_{(-i)}^2 = \\frac{(n - p) s^2 - \\frac{\\hat{e}_i^2}{1 - h_{ii}}}{n - p - 1}\n",
        "$$\n",
        "\n",
        "\n",
        "#### 5. Externally studentized Leave-one-out  residuals\n",
        "Leave-one-out residuals scaled by their own variance estimate:\n",
        "$$\n",
        "\\hat{r}_{(-i)} = \\frac{\\hat{e}_{(-i)}}{s_{(-i)} \\sqrt{1 - h_{ii}}},\n",
        "$$\n",
        "Externally studentized residuals highlight the influence of each observation if it were removed from the fit.\n",
        "\n",
        "In R:\n",
        "* `rstandard(model, ...)`\tinternally studentized\n",
        "* `rstudent(model, ...)`    \texternally studentized\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arprpj3FabP5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cakGRWCRMMl"
      },
      "source": [
        "# Let's code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-K-HUb6abSN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.api as sm\n",
        "\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpbM4dNrTOXv"
      },
      "outputs": [],
      "source": [
        "# Generate sample data for simple regression\n",
        "np.random.seed(42)\n",
        "n = 30\n",
        "X = np.random.normal(10, 2, n)\n",
        "sigma = 2  # Known true standard deviation\n",
        "Y = 2 * X + 5 + np.random.normal(0, sigma, n)  # Linear relationship\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7zQWKo7Sxwa"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compute coefficients manually\n",
        "# Construct design matrix with intercept\n",
        "X_matrix = np.column_stack((np.ones(n), X))\n",
        "Y_matrix = Y\n",
        "beta_hat = np.linalg.inv(X_matrix.T @ X_matrix) @ X_matrix.T @ Y_matrix\n",
        "\n",
        "# Predicted values and residuals\n",
        "Y_hat = X_matrix @ beta_hat\n",
        "residuals = Y_matrix - Y_hat  # classical residuals by hand\n",
        "\n",
        "# Assemble tidy DataFrame for statsmodels formulas\n",
        "data = pd.DataFrame({'Y': Y_matrix, 'X': X})\n",
        "\n",
        "# Variance and standardized residuals\n",
        "s_squared = np.sum(residuals**2) / (n - 2)  # unbiased variance estimate\n",
        "# Alternative (biased) estimator would be s2 = np.var(residuals)\n",
        "\n",
        "# Hat matrix and leverage values\n",
        "H = X_matrix @ np.linalg.inv(X_matrix.T @ X_matrix) @ X_matrix.T\n",
        "h_ii = np.diag(H)\n",
        "standardized_residuals_known_sigma = residuals / np.sqrt(sigma**2 * (1 - h_ii))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53SIgF-3VmAk"
      },
      "outputs": [],
      "source": [
        "# Compute trace of H\n",
        "trace_H_direct = np.trace(H)\n",
        "print(\"Trace of H:\", trace_H_direct)\n",
        "print(sum(h_ii))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYJS8xa9So3I"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Fit model using statsmodels (formula API)\n",
        "model_formula = smf.ols('Y ~ X', data=data).fit()\n",
        "\n",
        "# Fit model using statsmodels OLS with explicit design matrix\n",
        "model = sm.OLS(Y_matrix, X_matrix).fit()\n",
        "\n",
        "# Predicted values and residuals from formula fit\n",
        "Y_hat = model_formula.fittedvalues\n",
        "residuals = model_formula.resid\n",
        "\n",
        "# Leverage values (diagonal of Hat matrix)\n",
        "influence_formula = model_formula.get_influence()\n",
        "h_ii = influence_formula.hat_matrix_diag\n",
        "\n",
        "influence_matrix = model.get_influence()\n",
        "h_ii_matrix = influence_matrix.hat_matrix_diag\n",
        "\n",
        "print('Sum of leverages (formula fit):', h_ii.sum())\n",
        "print('Sum of leverages (matrix fit):', h_ii_matrix.sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFVh3rReSwue"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compute residual variants\n",
        "p = 2  # parameters: intercept and slope\n",
        "\n",
        "# 1. Standardized residuals (using known true sigma)\n",
        "standardized_residuals = residuals / np.sqrt(sigma**2 * (1 - h_ii))\n",
        "\n",
        "# 2. Internally studentized residuals (unknown sigma)\n",
        "s_squared = np.sum(residuals**2) / (n - p)\n",
        "studentized_residuals_internal = residuals / np.sqrt(s_squared * (1 - h_ii))\n",
        "\n",
        "# 3. Externally studentized residuals (deleted residuals)\n",
        "sigma_i_sq = ((n - p) * s_squared - (residuals**2) / (1 - h_ii)) / (n - p - 1)\n",
        "sigma_i_sq = np.clip(sigma_i_sq, a_min=0, a_max=None)\n",
        "sigma_i = np.sqrt(sigma_i_sq)\n",
        "studentized_residuals_external = residuals / (sigma_i * np.sqrt(1 - h_ii))\n",
        "\n",
        "# Reference residuals from statsmodels\n",
        "influence = model_formula.get_influence()\n",
        "model_studentized_residuals_internal = influence.resid_studentized\n",
        "model_studentized_residuals_external = influence.resid_studentized_external\n",
        "\n",
        "residuals_df = pd.DataFrame({\n",
        "    'Residuals (statsmodels)': residuals,\n",
        "    'Standardized (known sigma)': standardized_residuals,\n",
        "    'Studentized internal (manual)': studentized_residuals_internal,\n",
        "    'Studentized external (manual)': studentized_residuals_external,\n",
        "    'Studentized internal (statsmodels)': model_studentized_residuals_internal,\n",
        "    'Studentized external (statsmodels)': model_studentized_residuals_external\n",
        "})\n",
        "\n",
        "residuals_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OULMvw14WCvV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZn85ebQSo89"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compare variance estimates\n",
        "s_squared_manual = np.sum(residuals**2) / (n - 2)\n",
        "s_squared_statsmodels = model.mse_resid\n",
        "print(\"s_squared (manual):\", s_squared_manual)\n",
        "print(\"s_squared (statsmodels):\", s_squared_statsmodels)\n",
        "print(\"Difference:\", abs(s_squared_manual - s_squared_statsmodels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nM9NbaDwSo_A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPwfHRBEi16h"
      },
      "source": [
        "\n",
        "### Visual checks of residual distributions\n",
        "We compare raw residuals with standardized and studentized versions to see how scaling affects the normality assessment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxF3dZN3Ddxw"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Q-Q plots for different residual definitions\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "fig.suptitle(\"Q-Q plots for residual diagnostics\")\n",
        "\n",
        "stats.probplot(residuals, dist=\"norm\", plot=axes[0])\n",
        "axes[0].set_title(\"Raw residuals vs normal\")\n",
        "\n",
        "stats.probplot(studentized_residuals_internal, dist=\"norm\", plot=axes[1])\n",
        "axes[1].set_title(\"Studentized residuals (internal)\")\n",
        "\n",
        "stats.probplot(studentized_residuals_external, dist=\"t\", sparams=(n - p - 1,), plot=axes[2])\n",
        "axes[2].set_title(\"Studentized residuals (external)\")\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nR2_HM7j-CEe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_E3V0j4qMRcL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdVPNJ3F42oX"
      },
      "source": [
        "### Residual shape examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxrOANfJi16i"
      },
      "source": [
        "\n",
        "The four-panel layout lets us compare true disturbances, fitted residuals, and Q-Q plots for each simulated scenario.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Am-N3twCYU4m"
      },
      "outputs": [],
      "source": [
        "\n",
        "n_samples = 100\n",
        "\n",
        "# Generate datasets with specific residual characteristics\n",
        "def generate_data(case):\n",
        "    x = np.linspace(0, 10, n_samples)\n",
        "    if case == \"Right skewed\":\n",
        "        y = 2 * x + 5 + np.random.exponential(scale=1, size=n_samples)\n",
        "    elif case == \"Left skewed\":\n",
        "        y = 2 * x + 5 - np.random.exponential(scale=1, size=n_samples)\n",
        "    elif case == \"Tails too light\":\n",
        "        y = 2 * x + 5 + np.random.uniform(low=-1, high=1, size=n_samples)\n",
        "    elif case == \"Tails too heavy\":\n",
        "        y = 2 * x + 5 + np.random.standard_t(df=1, size=n_samples)\n",
        "    elif case == \"Bimodal distribution\":\n",
        "        y = 2 * x + 5 + np.concatenate([\n",
        "            np.random.normal(loc=-2, scale=0.5, size=n_samples//2),\n",
        "            np.random.normal(loc=2, scale=0.5, size=n_samples//2)\n",
        "        ])\n",
        "    elif case == \"True normal distribution\":\n",
        "        y = 2 * x + 5 + np.random.normal(scale=1, size=n_samples)\n",
        "    return x, y\n",
        "\n",
        "# Titles for different residual characteristics\n",
        "titles = [\"Right skewed\", \"Left skewed\", \"Tails too light\",\n",
        "          \"Tails too heavy\", \"Bimodal distribution\", \"True normal distribution\"]\n",
        "\n",
        "# Right = positive skewed, Left = Negative skewed\n",
        "\n",
        "# Adjusted code to add an additional row with scatter plots of the data and regression lines\n",
        "fig, axes = plt.subplots(4, 6, figsize=(24, 16))  # Adjusted figure size for additional row\n",
        "\n",
        "# Generate data, fit model, and plot scatter plots with regression lines, histograms, and QQ plots\n",
        "for i, title in enumerate(titles):\n",
        "    # Generate data with specific residual characteristics\n",
        "    x, y = generate_data(title)\n",
        "\n",
        "    # Plot scatter plot of data with regression line\n",
        "    x_with_const = sm.add_constant(x)\n",
        "    model = sm.OLS(y, x_with_const).fit()\n",
        "    y_pred = model.predict(x_with_const)\n",
        "\n",
        "    axes[0, i].scatter(x, y, color='orange', alpha=0.6, edgecolor='black')\n",
        "    axes[0, i].plot(x, y_pred, color='red', lw=2)\n",
        "    axes[0, i].set_title(f\"{title} Scatterplot\")\n",
        "    axes[0, i].set_xlabel(\"X\")\n",
        "    axes[0, i].set_ylabel(\"Y\")\n",
        "\n",
        "    # Plot histogram of disturbances\n",
        "    disturbances = y - (2 * x + 5)\n",
        "    axes[1, i].hist(disturbances, bins=20, edgecolor='black', alpha=0.7)\n",
        "    axes[1, i].set_title(f\"{title} Disturbances\")\n",
        "\n",
        "    # Plot histogram of residuals\n",
        "    residuals = model.resid\n",
        "    axes[2, i].hist(residuals, bins=20, edgecolor='black', alpha=0.7)\n",
        "    axes[2, i].set_title(f\"{title} Residuals\")\n",
        "\n",
        "    # Plot QQ plot of residuals\n",
        "    sm.qqplot(residuals, line='s', ax=axes[3, i])\n",
        "    axes[3, i].set_title(f\"{title} QQ Plot\")\n",
        "\n",
        "# Adjust layout and show plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUmy455hgfHK"
      },
      "source": [
        "# HW in separate notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jcmL-fAgiK7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}