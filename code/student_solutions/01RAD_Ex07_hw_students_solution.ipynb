{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francji1/01RAD/blob/main/code/01RAD_Ex07_hw_students_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 01RAD Exercise 7 - team work\n",
        "\n",
        "Authors: name1, name 2, name3"
      ],
      "metadata": {
        "id": "zabFwaT_y0Tz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Description of the Assignment\n",
        "\n",
        "The dataset `Boston` contains a total of 506 records from towns in the suburbs of Boston, MA, USA. The data originates from the study by Harrison, D., and Rubinfeld, D.L. (1978), *Hedonic prices and the demand for clean air*, J. Environ. Economics and Management, 5, 81â€“102.\n",
        "\n",
        "The dataset includes 14 variables. The goal is to explore the influence of 13 of them on the median value of owner-occupied homes (`medv`). Below is a description of the variables:\n",
        "\n",
        "| Feature   | Description                                                                 |\n",
        "|-----------|-----------------------------------------------------------------------------|\n",
        "| `crim`    | Per capita crime rate by town                                              |\n",
        "| `zn`      | Proportion of residential land zoned for lots over 25,000 sq.ft            |\n",
        "| `indus`   | Proportion of non-retail business acres per town                           |\n",
        "| `chas`    | Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)      |\n",
        "| `nox`     | Nitrogen oxides concentration (parts per 10 million)                       |\n",
        "| `rm`      | Average number of rooms per dwelling                                       |\n",
        "| `age`     | Proportion of owner-occupied units built prior to 1940                     |\n",
        "| `dis`     | Weighted mean of distances to five Boston employment centres               |\n",
        "| `rad`     | Index of accessibility to radial highways                                  |\n",
        "| `tax`     | Full-value property-tax rate per $10,000$                                   |\n",
        "| `ptratio` | Pupil-teacher ratio by  town    |                                            |\n",
        "| `black_tra`   | $1000\\left(\\text{black_pop} - 0.63\\right)^2$ where `black_pop` is the proportion of blacks by town       |\n",
        "| `lstat`   | Lower status of the population (percent)                                   |\n",
        "| `medv`    | Median value of owner-occupied homes in $1000s                             |\n",
        "\n",
        "---\n",
        "\n",
        "## Conditions and Scoring\n",
        "\n",
        "- Collaboration in the team is allowed and recommended.\n",
        "- This homework includes 14 questions.\n",
        "- Submit the homework in the corresponding `.ipynb` file, via MS Teams by the next week.\n",
        "---\n"
      ],
      "metadata": {
        "id": "rgsUsP_2QkIO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmgCFRDJyhcl"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RRGg62JQ3kmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# URL for the Boston housing dataset\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "\n",
        "# Reading the dataset\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "\n",
        "# Processing the dataset into features and target\n",
        "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "target = raw_df.values[1::2, 2]\n",
        "\n",
        "# Column names\n",
        "columns = [\n",
        "    \"crim\", \"zn\", \"indus\", \"chas\", \"nox\", \"rm\", \"age\",\n",
        "    \"dis\", \"rad\", \"tax\", \"ptratio\", \"black_tra\", \"lstat\"\n",
        "]\n",
        "boston_df = pd.DataFrame(data, columns=columns)\n",
        "boston_df[\"medv\"] = target\n",
        "\n",
        "\n",
        "boston_df\n",
        "boston_df.describe()"
      ],
      "metadata": {
        "id": "u9bLMFl13B-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Exploratory and Graphical Analysis\n",
        "\n",
        "### Question 01\n",
        "\n",
        "- Check for missing values and verify the dimensions of the dataset.\n",
        "- Summarize the descriptive statistics of all variables.\n",
        "- Plot a histogram and density estimate for the response variable `medv`.\n",
        "- Examine the frequency table of `medv` values and discuss whether rounding, truncation, or other issues are present.\n",
        "- Remove measurements deemed unreliable and discuss what this implies for the response model.\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UuW64uar6L5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boston_df.info()\n",
        "boston_df.describe()\n",
        "print(boston_df.isnull().sum())  # Check for missing values\n",
        "print(boston_df.shape)\n",
        "\n",
        "table = boston_df['medv'].value_counts().reset_index()\n",
        "print(table)"
      ],
      "metadata": {
        "id": "cfZ6HqPx6i4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(boston_df['medv'], kde=True, bins=30, color='blue', edgecolor='black')\n",
        "plt.title(\"Histogram and Density Estimate for MEDV\")\n",
        "plt.xlabel(\"MEDV\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GxEaRriUpxcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(boston_df['medv'].value_counts().sort_index())\n",
        "unreliable_measurements = boston_df[boston_df['medv'] == 50].index\n",
        "df_cleaned = boston_df.drop(unreliable_measurements)\n",
        "\n",
        "print(f\"Removed {len(unreliable_measurements)} unreliable measurements.\")\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df_cleaned['medv'], kde=True, bins=30, color='orange', edgecolor='black')\n",
        "plt.title(\"Histogram and Density Estimate for MEDV\")\n",
        "plt.xlabel(\"MEDV\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5u-tZ36qp3Ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Measurements with 'meadv' >= 50 removed. Model will be reliable for data with 'meadv' under 50 or only slightly above 50."
      ],
      "metadata": {
        "id": "LLea3rnmtVZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Regression Model: Median Price and Crime\n",
        "\n",
        "### Question 2\n",
        "\n",
        "- Build a simple linear regression model to examine if the crime rate (`crim`) affects the median value of homes (`medv`).\n",
        "- If there is an effect, determine how much the housing price decreases as the crime rate increases.\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_EyeT_pK7LkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.formula.api as smf\n",
        "formula = 'medv ~ (crim)'\n",
        "\n",
        "# Fit an OLS model with interactions\n",
        "model = smf.ols(formula, data=df_cleaned).fit()\n",
        "\n",
        "# Display model summary\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "ANrG30oBvTyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with intercept can be interpreted as how the home price varies if there is higher crime rate from the mean home price. The R2 statistics is quite low, although for crude data and only one parameter it is not bad.\n",
        "The model shows how the median house price varies from the price when crime rate is 0, then for every unit the crime rate increases, house value drops by $400.\n"
      ],
      "metadata": {
        "id": "VfzZ-8clvZ0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3\n",
        "\n",
        "- Experiment with power and logarithmic transformations of the response variable (`medv`).\n",
        "- To find the optimal power transformation, plot the log-likelihood profile for the Box-Cox transformation and compare it with a logarithmic transformation.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Pl2lU4XEogBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned['log_medv'] = np.log(df_cleaned['medv'])\n",
        "sns.histplot(df_cleaned['log_medv'], kde=True, bins=30, color='blue', edgecolor='black')\n",
        "plt.title(\"Histogram of Log-Transformed MEDV\")\n",
        "plt.xlabel(\"log(MEDV)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AMC9EHhGwGHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import boxcox\n",
        "from scipy.stats import boxcox_llf\n",
        "from scipy.stats import chi2\n",
        "import scipy.stats as stats\n",
        "\n",
        "df_cleaned['medv_positive'] = df_cleaned['medv']\n",
        "boxcox_transformed, lambda_opt = boxcox(df_cleaned['medv_positive'])\n",
        "\n",
        "df_cleaned['boxcox_medv'] = boxcox_transformed\n",
        "\n",
        "print(f\"Optimal lambda for Box-Cox Transformation: {lambda_opt}\")\n",
        "\n",
        "lambda_values = np.linspace(-2, 2, 100)\n",
        "\n",
        "log_likelihoods = [boxcox_llf(lmb, df_cleaned['medv_positive']) for lmb in lambda_values]\n",
        "\n",
        "max_log_likelihood = max(log_likelihoods)\n",
        "\n",
        "threshold = max_log_likelihood - chi2.ppf(0.95, df=1) / 2\n",
        "\n",
        "lambda_conf_interval = lambda_values[\n",
        "    (log_likelihoods >= threshold)\n",
        "]\n",
        "\n",
        "lambda_low = min(lambda_conf_interval)\n",
        "lambda_high = max(lambda_conf_interval)\n",
        "\n",
        "log_likelihoods_function = stats.boxcox_llf(0, df_cleaned['medv_positive'])\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(lambda_values, log_likelihoods, label='Log-Likelihood')\n",
        "plt.axvline(lambda_opt, color='red', linestyle='--', label=f\"Optimal lambda = {lambda_opt:.2f}\")\n",
        "plt.axvline(lambda_low, color=\"green\", linestyle=\"--\", label=f\"95% CI Lower = {lambda_low:.2f}\")\n",
        "plt.axvline(lambda_high, color=\"blue\", linestyle=\"--\", label=f\"95% CI Upper = {lambda_high:.2f}\")\n",
        "plt.axhline(threshold, color=\"gray\", linestyle=\"--\", label=\"95% CI Threshold\")\n",
        "plt.scatter([0], [log_likelihoods_function], color='orange', label=f\"lambda = {0}\")\n",
        "plt.title(\"Log-Likelihood Profile for Box-Cox Transformation\")\n",
        "plt.xlabel(\"Lambda\")\n",
        "plt.ylabel(\"Log-Likelihood\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LmPv4MjYxSqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(df_cleaned['log_medv'], kde=True, color='blue', bins=30)\n",
        "plt.title(\"Logarithmic Transformation (lambda = 0)\")\n",
        "plt.xlabel(\"log(MEDV)\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(df_cleaned['boxcox_medv'], kde=True, color='green', bins=30)\n",
        "plt.title(f\"Box-Cox Transformation (Optimal lambda = {lambda_opt:.2f})\")\n",
        "plt.xlabel(\"Box-Cox Transformed MEDV\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zhdM7KViyhK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lambda 0.5 was chosen as it is close to 0.4 and easier to apply and interpret"
      ],
      "metadata": {
        "id": "L7V4RUJFzVJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "X = sm.add_constant(df_cleaned['crim'])\n",
        "\n",
        "model_log = sm.OLS(df_cleaned['log_medv'], X).fit()\n",
        "model_boxcox = sm.OLS(df_cleaned['boxcox_medv'], X).fit()\n",
        "\n",
        "print(\"Logarithmic Transformation Model Summary:\")\n",
        "print(model_log.summary())\n",
        "\n",
        "print(f\"\\nBox-Cox Transformation with lambda = {lambda_opt:.2f} Model Summary:\")\n",
        "print(model_boxcox.summary())\n"
      ],
      "metadata": {
        "id": "44Zeu4V4zUgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "\n",
        "model_log_resid = model_log.resid\n",
        "sns.histplot(model_log_resid, kde=True, color='blue')\n",
        "plt.title(\"Residuals of Log-Transformed Model\")\n",
        "\n",
        "model_boxcox_resid = model_boxcox.resid\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(model_boxcox_resid, kde=True, color='green')\n",
        "plt.title(\"Residuals of Box-Cox-Transformed Model\")\n",
        "\n",
        "\n",
        "# Calculate studentized residuals for each model\n",
        "residuals_log_student = model_log.get_influence().resid_studentized_internal\n",
        "residuals_boxcox_student = model_boxcox.get_influence().resid_studentized_internal\n",
        "\n",
        "\n",
        "residuals_df = pd.DataFrame({\n",
        "    'Logarithmic': residuals_log_student,\n",
        "    'Box-Cox': residuals_boxcox_student\n",
        "})\n",
        "fig, axes = plt.subplots(1,2, figsize=(12, 5))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(residuals_df.columns):\n",
        "    axes[i].plot(residuals_df.index, residuals_df[col], marker='o', linestyle='', alpha=0.5)\n",
        "    axes[i].axhline(0, color='gray', linestyle='--')\n",
        "    axes[i].set_title(f\"Studentized Residuals: {col} transformation\")\n",
        "    axes[i].set_xlabel(\"Index\")\n",
        "    axes[i].set_ylabel(\"Studentized Residuals\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# QQ-plots for studentized residuals\n",
        "fig, axes = plt.subplots(1,2,  figsize=(12, 5))\n",
        "for i, col in enumerate(residuals_df.columns):\n",
        "    sm.qqplot(residuals_df[col], line='45', ax=axes[i])\n",
        "    axes[i].set_title(f\"QQ-plot: {col} transformation\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h7bJjeLb1EdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 4\n",
        "\n",
        "- Based on the simple linear model and on the model with logarithmic transformations of the response variable, estimate the increase or decrease in housing prices for a one-unit change in the crime rate (`crim`).\n",
        "- Provide the correct interpretation from both models.\n",
        "---"
      ],
      "metadata": {
        "id": "OOVZWpzWovTM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The price change under the model with just intercept and cirme rate, without data transformation was already explained. If we perform the logarithmic transformation, the crime rate coefficient has to be interpreted as a percentage change, that is calculated as: 100*(e^{beta_crime} - 1)\n",
        "because the values need to be transromed back using the exponential and then interpreted as proportional change"
      ],
      "metadata": {
        "id": "k3RQfNaC1byo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 5\n",
        "\n",
        "- Keep the logarithmic transformation of the response (`medv`) and try transforming the independent variable (`crim`).\n",
        "- Use techniques such as piecewise constant transformations, or polynomial transformations (quadratic and cubic).\n",
        "- Use information from plots such as Component-Residual Plots (Partial Residual Plots) and Partial Regression Plots to guide your transformations.\n",
        "- Discuss whether these models can be compared using an F-test. If applicable, perform the test and interpret the results.\n",
        "---"
      ],
      "metadata": {
        "id": "Rvybbjw5pISl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned['crim_binned'] = pd.cut(df_cleaned['crim'], bins=[-np.inf, 1, 5, 10, np.inf], labels=['low', 'medium', 'high', 'very_high'])\n",
        "\n",
        "crim_dummies = pd.get_dummies(df_cleaned['crim_binned'], drop_first=True)\n",
        "X_piecewise = sm.add_constant(crim_dummies)\n",
        "\n",
        "model_piecewise = sm.OLS(df_cleaned['log_medv'], X_piecewise.astype(float)).fit()\n",
        "print(model_piecewise.summary())"
      ],
      "metadata": {
        "id": "vH_dtDIp1Leh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nejsem si jisty co to znamena."
      ],
      "metadata": {
        "id": "8rBJUvOP75yA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned['crim_squared'] = df_cleaned['crim'] ** 2\n",
        "df_cleaned['crim_cubed'] = df_cleaned['crim'] ** 3\n",
        "\n",
        "X_poly2 = sm.add_constant(df_cleaned[['crim', 'crim_squared']])\n",
        "model_poly2 = sm.OLS(df_cleaned['log_medv'], X_poly2.astype(float)).fit()\n",
        "\n",
        "X_poly3 = sm.add_constant(df_cleaned[['crim', 'crim_squared', 'crim_cubed']])\n",
        "model_poly3 = sm.OLS(df_cleaned['log_medv'], X_poly3.astype(float)).fit()\n",
        "\n",
        "print(\"Quadratic Model Summary:\")\n",
        "print(model_poly2.summary())\n",
        "\n",
        "print(\"\\nCubic Model Summary:\")\n",
        "print(model_poly3.summary())"
      ],
      "metadata": {
        "id": "rpRT8Pzw4r_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even higher order terms seem to be statistically significant and R2 and even adj-R2 improved when moving to cubed variables. Other statistics remained rather same."
      ],
      "metadata": {
        "id": "5Rao3kLI6PIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.graphics.regressionplots import plot_ccpr\n",
        "from statsmodels.graphics.regressionplots import plot_partregress\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "plot_ccpr(model_poly2, 'crim', ax=ax)\n",
        "plot_ccpr(model_poly3, 'crim', ax=ax)\n",
        "plt.title(\"Component-Residual Plot for crim\")\n",
        "plt.show()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(18, 8))\n",
        "plot_partregress('log_medv', 'crim', ['crim_squared'], data=df_cleaned, ax=ax)\n",
        "plot_partregress('log_medv', 'crim',['crim_cubed'], data=df_cleaned, ax=ax)\n",
        "plt.title(\"Partial Regression Plot for crim\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q8wHeroc5Mvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm.graphics.plot_partregress_grid(model_poly2)\n",
        "sm.graphics.plot_partregress_grid(model_poly3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VZku8deH9yis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis: linear model is sufficient vs. the higher orders have large significance. Since the squared and cubed crime had good statistical significance it is suitable to compare them using the F statistics."
      ],
      "metadata": {
        "id": "eZAKAaJT6nUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare linear model to quadratic model\n",
        "f_test_result = model_poly2.compare_f_test(model)\n",
        "print(f\"F-test result (linear vs. quadratic): {f_test_result}\")\n",
        "\n",
        "# Compare linear to cubic model\n",
        "f_test_result2 = model_poly3.compare_f_test(model)\n",
        "print(f\"F-test result (quadratic vs. cubic): {f_test_result2}\")"
      ],
      "metadata": {
        "id": "MY5gzUEM5yM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "linear vs. quadratic results: F=288844.00, p=0.0, df=1.0, which indicatec that the cubic model fits significantly better than the linar one, however the improvement is not large going from quadratic to cubic model."
      ],
      "metadata": {
        "id": "zMJvrNhr7GXa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 6\n",
        "\n",
        "- Select one of the previous models, justify your choice, and validate it using the appropriate hypothesis tests for residuals (normality, homoscedasticity, etc.).\n",
        "- Use diagnostic plots such as Q-Q plots, residuals vs. fitted values, and others to evaluate the model's assumptions.\n",
        "---\n"
      ],
      "metadata": {
        "id": "e03oGgCkzOm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare quadratic to cubic\n",
        "f_test_result3 = model_poly3.compare_f_test(model_poly2)\n",
        "print(f\"F-test result (quadratic vs. cubic): {f_test_result3}\")"
      ],
      "metadata": {
        "id": "X5V9hZS69tnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Residuals vs. Fitted Values\n",
        "plt.figure(figsize=(8, 6))\n",
        "residuals_poly2 = model_poly2.resid\n",
        "sns.residplot(x=model_poly2.fittedvalues, y=residuals_poly2, lowess=True, line_kws={'color': 'red'})\n",
        "plt.title('Residuals for quadratic model vs Fitted Values')\n",
        "plt.xlabel('Fitted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3_arueP3_hAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Residuals vs. Fitted Values\n",
        "plt.figure(figsize=(8, 6))\n",
        "residuals_poly3 = model_poly3.resid\n",
        "sns.residplot(x=model_poly3.fittedvalues, y=residuals_poly3, lowess=True, line_kws={'color': 'red'})\n",
        "plt.title('Residuals for cubic model vs Fitted Values')\n",
        "plt.xlabel('Fitted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "flW8ZU9gBHzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Q-Q plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "stats.probplot(residuals_poly2, dist=\"norm\", plot=plt)\n",
        "plt.title('Q-Q Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IVqiFFfDBRUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Q-Q plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "stats.probplot(residuals_poly3, dist=\"norm\", plot=plt)\n",
        "plt.title('Q-Q Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NBXnDAriBaWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.diagnostic import het_breuschpagan\n",
        "\n",
        "X_quad_const = sm.add_constant(df_cleaned[['crim', 'crim_squared']])\n",
        "\n",
        "bp_test_stat, bp_test_p_value, _, _ = het_breuschpagan(residuals_poly2, X_quad_const)\n",
        "print(f\"Breusch-Pagan test statistic: {bp_test_stat}, p-value: {bp_test_p_value}\")\n",
        "\n",
        "X_quad_const = sm.add_constant(df_cleaned[['crim', 'crim_squared']])\n",
        "\n",
        "bp_test_stat, bp_test_p_value, _, _ = het_breuschpagan(residuals_poly3, X_quad_const)\n",
        "print(f\"Breusch-Pagan test statistic: {bp_test_stat}, p-value: {bp_test_p_value}\")"
      ],
      "metadata": {
        "id": "RZDroBDdBjNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By simply observing the plotted residuals one could see that there is no signifficant heteroskedacity. I added the Breusch-Pagan test here for completeness, where we failed to reject the null hypothesis that there is heteroskedacity. Durbin-Watson statistics for both models was around 0.8, which suggests some autocorrelation (which appears with the Durbin-Watson statistics being near 0)."
      ],
      "metadata": {
        "id": "7MYm1owDChqg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on D-W statistics, QQ plots and residual plots being largely the same with the quadratic and the cubic model and seeing no significant improvement taking the cubic model... R2 didn't improve much and the F-test suggested that although there is statistical signifficance in taking the cubic model, the improvement is not worth it. I would pick the quadratic model, since the interpretation is more straight forward and it is simpler and also offers good precision."
      ],
      "metadata": {
        "id": "3d1-7TN6DzyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Multivariate Regression Model\n",
        "\n",
        "### Question 7\n",
        "\n",
        "- Build a multivariate linear regression model with a logarithmic transformation of the response (`medv`).\n",
        "- Explore relationships between housing prices and other independent variables in an additive model (no interactions).\n",
        "- Use criteria such as AIC, BIC, $ R^2 $, and F-statistics to select the best model.\n",
        "- Investigate whether the relationship between `crim` and `medv` can be explained by other variables, such as proximity to highways or pollution levels.\n",
        "---"
      ],
      "metadata": {
        "id": "INE7xTEg7NCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.head()"
      ],
      "metadata": {
        "id": "oKxTl6HsH1Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned['log_medv'] = np.log(df_cleaned['medv'])\n",
        "\n",
        "X = df_cleaned[['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black_tra', 'lstat']]\n",
        "\n",
        "# Adds constant term to fit intercept\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "model = sm.OLS(df_cleaned['log_medv'], X).fit()\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "eEaexWK2HCZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "zn, indus, chas and age don't seem to be statistically significant in the model without interactions. R2 is quite high at 0.8 and D-W near 1, suggesting that there is no apparent autocorrelation."
      ],
      "metadata": {
        "id": "w62qp0zUIQ94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_cleaned[['crim', 'nox', 'rm', 'dis', 'rad', 'tax', 'ptratio', 'black_tra', 'lstat']]\n",
        "\n",
        "# Adds constant term to fit intercept\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "model = sm.OLS(df_cleaned['log_medv'], X).fit()\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "ywnLK3pHJRrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "both AIC and BIC are larger for this reduced model, all the variables are now statistically significant and R2, adj-R2 didn't drop. D-W remains the same, while F-statistics value increased indicating that this model is statistically more significant than the larger one."
      ],
      "metadata": {
        "id": "UFd2oQ35Jd5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 8\n",
        "\n",
        "- Incorporate `crim` (crime rate) into the final model and compare how its influence on the median housing price differs from the simple regression model with a logarithmic transformation of the response (from Question 4).\n",
        "- Estimate the reduction in median housing price for a one-unit increase in the crime rate per 1,000 residents.\n",
        "---"
      ],
      "metadata": {
        "id": "85OK93iBzmRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_simple = sm.add_constant(df_cleaned[['crim']])\n",
        "model_simple = sm.OLS(df_cleaned['log_medv'], X_simple).fit()\n",
        "print(model_simple.summary())"
      ],
      "metadata": {
        "id": "JZpCEIniJ5Bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Percentage change in median house value when crime rate per 1000 residents changes by one unit: 100 * (e^beta_crim - 1) = 100 * (e^{-0.02} - 1) = -1.98%"
      ],
      "metadata": {
        "id": "gh42JFLRkrfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_multivariate = df_cleaned[['crim', 'nox', 'dis', 'rad', 'zn', 'indus', 'chas', 'rm', 'age', 'ptratio', 'black_tra', 'lstat']]\n",
        "X_multivariate = sm.add_constant(X_multivariate)\n",
        "\n",
        "model_multivariate = sm.OLS(df_cleaned['log_medv'], X_multivariate).fit()\n",
        "print(model_multivariate.summary())"
      ],
      "metadata": {
        "id": "o-jlLhSRj7YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Percentage change in median house value in the multivariate model, when crime rate per 1000 residents changes by one unit: 100 * (e^beta_crim - 1) = 100 * (e^{-0.01} - 1) = -1%"
      ],
      "metadata": {
        "id": "8GeeWdgfkQsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_vars = df_cleaned[['crim', 'nox', 'dis', 'rad', 'log_medv']]\n",
        "correlation_matrix = selected_vars.corr()\n",
        "print(correlation_matrix)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u9iPMcR7lpNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 9\n",
        "\n",
        "- Present your final predictive model for `medv` and discuss the key parameters such as $ R^2 $, $ \\sigma $, and F-statistics.\n",
        "- Compare the final model with the simple linear model from Question 6. Discuss how these parameters have changed and whether this change was expected.\n",
        "- Validate the model both graphically and using hypothesis tests.\n",
        "---"
      ],
      "metadata": {
        "id": "0fUKctIvzn3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_no_nox_dis_rad = df_cleaned[['crim', 'zn', 'indus', 'chas', 'rm', 'age', 'ptratio', 'black_tra', 'lstat']]\n",
        "X_no_nox_dis = sm.add_constant(X_no_nox_dis_rad)\n",
        "model_no_nox_dis_rad = sm.OLS(df_cleaned['log_medv'], X_no_nox_dis_rad).fit()\n",
        "f_test_result = model_multivariate.compare_f_test(model_no_nox_dis_rad)\n",
        "print(f\"F-statistic: {f_test_result[0]:.4f}, p-value: {f_test_result[1]:.4f}\")\n",
        "print(\"===============================================\")\n",
        "print(model_no_nox_dis_rad.summary())"
      ],
      "metadata": {
        "id": "sA-VGVSqmI__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We reject the null hypothesis that the simpler model is as good as the full model, even though the R2 is higher. This could be due to multicolinearity in the omitted variables."
      ],
      "metadata": {
        "id": "GshQpihRmvgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "residuals = model.resid\n",
        "\n",
        "SSE = np.sum(residuals**2)\n",
        "n = len(model.model.endog)\n",
        "p = model.df_model + 1\n",
        "sigma = np.sqrt(SSE / (n - p))\n",
        "\n",
        "residuals_mul = model_multivariate.resid\n",
        "SSE_mul = np.sum(residuals_mul**2)\n",
        "n_mul = len(model_multivariate.model.endog)\n",
        "p_mul = model_multivariate.df_model + 1\n",
        "sigma_mul = np.sqrt(SSE_mul / (n_mul - p_mul))\n",
        "\n",
        "residuals_simpler = model_no_nox_dis_rad.resid\n",
        "SSE_simpler = np.sum(residuals_simpler**2)\n",
        "n_simpler = len(model_no_nox_dis_rad.model.endog)\n",
        "p_simpler = model_no_nox_dis_rad.df_model + 1\n",
        "sigma_simpler = np.sqrt(SSE_simpler / (n_simpler - p_simpler))\n",
        "\n",
        "\n",
        "print(f\"Standard Error of Residuals (sigma) for Linear Model: {sigma}\")\n",
        "print(\"R2 for Linear Model: 0.320\")\n",
        "print(\"F-stat for Linear Model: 230\")\n",
        "print(\"===============\")\n",
        "\n",
        "print(f\"Standard Error of Residuals (sigma) for Multivariate Model: {sigma_mul}\")\n",
        "print(\"R2 for Multivariate Model: 0.78\")\n",
        "print(\"F-stat for Multivariate Model: 142\")\n",
        "\n",
        "print(\"===============\")\n",
        "print(\"For completness we include the model without variables: nox, dis, rad\")\n",
        "print(f\"Standard Error of Residuals (sigma) for Simple Model: {sigma_simpler}\")\n",
        "print(\"R2 for Simple Model: 0.993\")\n",
        "print(\"F-stat for Simple Model: 7900\")"
      ],
      "metadata": {
        "id": "f7mAYVV1ps7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing nox, dis and rad likely results in overfitting on the available data. In this scenario, the simple linear model captures only 32% of the variability in data, while it offers a good fit."
      ],
      "metadata": {
        "id": "tj5EQx_Ar2m2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
        "plt.title('Q-Q Plot, Linear Model')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cp7SJ8cfsmjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "stats.probplot(residuals_mul, dist=\"norm\", plot=plt)\n",
        "plt.title('Q-Q Plot, Multivariate Model')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aJD27uvTsqAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(model.fittedvalues, model.resid)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.title(\"Residuals vs. Fitted Values, Linear Model\")\n",
        "plt.xlabel(\"Fitted Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FZEuTorCtVFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(model_multivariate.fittedvalues, model_multivariate.resid)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.title(\"Residuals vs. Fitted Values, Multivariate Model\")\n",
        "plt.xlabel(\"Fitted Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FfjyAC0XtXUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shapiro_test_linear_model = stats.shapiro(model.resid)\n",
        "print(\"Shapiro-Wilk test statistic for Linear Model:\", shapiro_test_linear_model.statistic, \"p-value:\", shapiro_test_linear_model.pvalue)\n",
        "\n",
        "shapiro_test_mul = stats.shapiro(model_multivariate.resid)\n",
        "print(\"Shapiro-Wilk test statistic for Multivariate Model:\", shapiro_test_mul.statistic, \"p-value:\", shapiro_test_mul.pvalue)\n",
        "\n",
        "import statsmodels.stats.api as sms\n",
        "bp_test = sms.het_breuschpagan(model.resid, model.model.exog)\n",
        "print(\"Breusch-Pagan test statistic for Linear Model:\", bp_test[0], \"p-value:\", bp_test[1])\n",
        "\n",
        "bp_test = sms.het_breuschpagan(model_multivariate.resid, model_multivariate.model.exog)\n",
        "print(\"Breusch-Pagan test statistic for Multivariate Model:\", bp_test[0], \"p-value:\", bp_test[1])\n",
        "dw_test = sm.stats.durbin_watson(model.resid)\n",
        "print(\"Durbin-Watson test statistic for Linear Model:\", dw_test)\n",
        "dw_test = sm.stats.durbin_watson(model_multivariate.resid)\n",
        "print(\"Durbin-Watson test statistic: for Multivariate Model\", dw_test)"
      ],
      "metadata": {
        "id": "kOP8vzIDtvYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both the linear model and multivariate model show signs of problems with normality, heteroscedasticity."
      ],
      "metadata": {
        "id": "v9Re8OgWvOzW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 10\n",
        "\n",
        "- Based on your final model, answer whether reducing the crime rate in an area would lead to an increase in housing prices in that area.\n",
        "- Provide an explanation based on your findings.\n",
        "---"
      ],
      "metadata": {
        "id": "vJkI3DApzuVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned['crim_squared'] = df_cleaned['crim'] ** 2\n",
        "X_multivariate_square_crim = df_cleaned[['crim', 'nox', 'dis', 'rad', 'rm', 'ptratio', 'black_tra', 'lstat', 'crim_squared']]\n",
        "X_multivariate_square_crim = sm.add_constant(X_multivariate_square_crim)\n",
        "\n",
        "model_multivariate_square_crim = sm.OLS(df_cleaned['log_medv'], X_multivariate_square_crim).fit()\n",
        "print(model_multivariate_square_crim.summary())\n",
        "\n",
        "shapiro_test_mul_sq = stats.shapiro(model_multivariate_square_crim.resid)\n",
        "print(\"Shapiro-Wilk test statistic for Multivariate Model with Square crim:\", shapiro_test_mul_sq.statistic, \"p-value:\", shapiro_test_mul_sq.pvalue)\n",
        "\n",
        "bp_test_mul_sq = sms.het_breuschpagan(model_multivariate_square_crim.resid, model_multivariate_square_crim.model.exog)\n",
        "print(\"Breusch-Pagan test statistic for Multivariate Model:\", bp_test_mul_sq[0], \"p-value:\", bp_test_mul_sq[1])\n",
        "dw_test_mul_sq = sm.stats.durbin_watson(model_multivariate_square_crim.resid)\n",
        "print(\"Durbin-Watson test statistic for Linear Model:\", dw_test_mul_sq)\n",
        "\n",
        "residuals_mul_sq = model_multivariate_square_crim.resid\n",
        "plt.figure(figsize=(8, 6))\n",
        "stats.probplot(residuals_mul_sq, dist=\"norm\", plot=plt)\n",
        "plt.title('Q-Q Plot, Multivariate Model with Squared crim')\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(model_multivariate_square_crim.fittedvalues,model_multivariate_square_crim.resid)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.title(\"Residuals vs. Fitted Values, Multivariate Model with Square crim\")\n",
        "plt.xlabel(\"Fitted Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jxtJmXBBvRlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Question 11: Compare Coefficients in Simple Models\n",
        "\n",
        "Investigate, if the transformation of `black_pop` into `black_tra` was  misleading and suggestive. Add new variable `black_pop` into the data frame by inverse of orginal transformation.\n",
        "\n",
        "- Build two separate simple linear regression models:\n",
        "  1. Predicting `medv` using `black_tra`.\n",
        "  2. Predicting `medv` using `black_pop`.\n",
        "- Compare the coefficients from both models and interpret the differences.\n",
        "- Discuss whether the transformation of `black_tra` appears to exaggerate or diminish its relationship with `medv`.\n",
        "---"
      ],
      "metadata": {
        "id": "u5dQeJXeJF-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned['black_pop'] = np.sqrt(df_cleaned['black_tra'] / 1000) + 0.63\n",
        "X_black_tra = sm.add_constant(df_cleaned['black_tra'])\n",
        "y_medv = df_cleaned['log_medv']\n",
        "model_black_tra = sm.OLS(y_medv, X_black_tra).fit()\n",
        "\n",
        "X_black_pop = sm.add_constant(df_cleaned['black_pop'])\n",
        "model_black_pop = sm.OLS(y_medv, X_black_pop).fit()\n",
        "\n",
        "# Print the summary for both models\n",
        "print(\"Model 1 (black_tra):\\n\", model_black_tra.summary())\n",
        "print(\"Model 2 (black_pop):\\n\", model_black_pop.summary())"
      ],
      "metadata": {
        "id": "uAl5CKQFyp1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The transformation of black_pop into black_tra diminishes the relationship with medv because it introduces non-linearity and compresses the range of values and that is why I think the transformation is unnecessary and has less direct explainability compared to black_tra."
      ],
      "metadata": {
        "id": "kjbqVxEF35bJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import f_regression\n",
        "\n",
        "y = df_cleaned['medv']\n",
        "\n",
        "X_all = df_cleaned.drop(columns=['log_medv', 'black_pop', 'crim_binned', 'medv_positive', 'boxcox_medv', 'medv', 'crim_cubed'])\n",
        "X_all = sm.add_constant(X_all)\n",
        "print(X_all.head())"
      ],
      "metadata": {
        "id": "VPUf89C43Ozs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "had to remove crim_binned since it is a cathegory variable that is not compatible with the code.\n"
      ],
      "metadata": {
        "id": "KK9FfQreHAW5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Question 12: Stepwise Regression with `black_tra`\n",
        "\n",
        "- Perform stepwise regression starting with all independent variables, including `black_tra`, as predictors of `medv`.\n",
        "- Evaluate whether `black_tra` remains significant in the final model after stepwise variable selection.\n",
        "- Discuss whether its significance changes when considered alongside other predictors.\n",
        "---"
      ],
      "metadata": {
        "id": "IKLiKV2T1AE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_elimination_aic_bic(X, y, criterion=\"AIC\"):\n",
        "    included = list(X.columns)\n",
        "    best_metric = float(\"inf\")\n",
        "    best_model = None\n",
        "\n",
        "    while True:\n",
        "        model_stepwise = sm.OLS(y, sm.add_constant(X[included])).fit()\n",
        "        current_metric = model_stepwise.aic if criterion.upper() == \"AIC\" else model_stepwise.bic\n",
        "\n",
        "        if current_metric < best_metric:\n",
        "            best_metric = current_metric\n",
        "            best_model = model_stepwise\n",
        "        else:\n",
        "            break\n",
        "        pvalues = model_stepwise.pvalues.iloc[1:]\n",
        "        worst_feature = pvalues.idxmax()\n",
        "\n",
        "        if pvalues[worst_feature] > 0.05:\n",
        "            print(f\"Removing '{worst_feature}' with p-value {pvalues[worst_feature]:.4f} and {criterion} {current_metric:.2f}\")\n",
        "            included.remove(worst_feature)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return best_model, included\n",
        "\n",
        "model_backward_aic, selected_features_aic = backward_elimination_aic_bic(X_all, y, criterion=\"AIC\")\n",
        "print(\"Selected features based on AIC:\", selected_features_aic)\n",
        "print(model_backward_aic.summary())\n",
        "\n",
        "model_backward_bic, selected_features_bic = backward_elimination_aic_bic(X_all, y, criterion=\"BIC\")\n",
        "print(\"Selected features based on BIC:\", selected_features_bic)\n",
        "print(model_backward_bic.summary())\n",
        "\n"
      ],
      "metadata": {
        "id": "LRmfvwHkGxrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_aic_no_black_tra = df_cleaned.drop(columns=['log_medv', 'black_pop', 'crim_binned', 'medv_positive', 'boxcox_medv', 'medv', 'crim_cubed', 'black_tra', 'chas', 'indus', 'crim_squared'])\n",
        "model_backawrd_aic_no_black_tra = sm.OLS(df_cleaned['medv'], X_aic_no_black_tra).fit()\n",
        "f_test_result_aic = model_backward_aic.compare_f_test(model_backawrd_aic_no_black_tra)\n",
        "print(f\"F-statistic comparing model from stepwise to one without balck_tra: {f_test_result[0]:.4f}, p-value: {f_test_result[1]:.4f}\")"
      ],
      "metadata": {
        "id": "zk2BCY7YK4y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The F-stat suggests that we reject the null hypothesis that the model without black_tra is as good as the one including it. So black_tra is a significant predictor."
      ],
      "metadata": {
        "id": "V-oxfrfALw85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Question 13: Stepwise Regression with `black_pop`\n",
        "\n",
        "- Repeat the stepwise regression from Question 12, but this time replace `black_tra` with `black_pop`.\n",
        "- Evaluate whether `black_pop` remains significant in the final model.\n",
        "- Compare its significance to that of `black_tra` from Question 12.\n",
        "---"
      ],
      "metadata": {
        "id": "4rM52aRE1lFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df_cleaned['medv']\n",
        "\n",
        "X_all_pop = df_cleaned.drop(columns=['crim_binned', 'black_tra', 'medv_positive', 'boxcox_medv', 'medv', 'crim_cubed'])\n",
        "print(X_all_pop.head())"
      ],
      "metadata": {
        "id": "_clj4x3SMp59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def backward_elimination_aic_bic(X, y, criterion=\"AIC\"):\n",
        "    included = list(X.columns)\n",
        "    best_metric = float(\"inf\")\n",
        "    best_model = None\n",
        "\n",
        "    while True:\n",
        "        model_stepwise = sm.OLS(y, sm.add_constant(X[included])).fit()\n",
        "        current_metric = model_stepwise.aic if criterion.upper() == \"AIC\" else model_stepwise.bic\n",
        "\n",
        "        if current_metric < best_metric:\n",
        "            best_metric = current_metric\n",
        "            best_model = model_stepwise\n",
        "        else:\n",
        "            break\n",
        "        pvalues = model_stepwise.pvalues.iloc[1:]\n",
        "        worst_feature = pvalues.idxmax()\n",
        "\n",
        "        if pvalues[worst_feature] > 0.05:\n",
        "            print(f\"Removing '{worst_feature}' with p-value {pvalues[worst_feature]:.4f} and {criterion} {current_metric:.2f}\")\n",
        "            included.remove(worst_feature)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return best_model, included\n",
        "\n",
        "model_backward_aic_pop, selected_features_aic_pop = backward_elimination_aic_bic(X_all_pop, y, criterion=\"AIC\")\n",
        "print(\"Selected features based on AIC:\", selected_features_aic_pop)\n",
        "print(model_backward_aic_pop.summary())\n",
        "\n",
        "model_backward_bic_pop, selected_features_bic_pop = backward_elimination_aic_bic(X_all_pop, y, criterion=\"BIC\")\n",
        "print(\"Selected features based on BIC:\", selected_features_bic_pop)\n",
        "print(model_backward_bic_pop.summary())"
      ],
      "metadata": {
        "id": "9MZoq03ENN_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "balck_pop was removed by the stepwise regression, so there is no point in running the F-stat test to compare them. black_tra is statistically significant, while black_pop is not."
      ],
      "metadata": {
        "id": "Y29FkDEMP-Qs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 14: Impact on Predictions\n",
        "\n",
        "- For both the models from Questions 12 and 13 (stepwise regression with `black_tra` and `black_pop`), compare their predictions for `medv`.\n",
        "- Specifically:\n",
        "  1. Calculate predictions for a range of values of `black_tra` and `black_pop`.\n",
        "  2. Plot the predictions and interpret whether the two variables result in substantially different predicted values.\n",
        "- Discuss whether the transformed variable (`black_tra`) or its proportion counterpart (`black_pop`) leads to any noticeable bias or distortion in predictions.\n",
        "---"
      ],
      "metadata": {
        "id": "MuPW6uka1sdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pop\n",
        "matrix_pop =  X_all_pop[selected_features_bic_pop].values\n",
        "matrix_with_intercept_pop = np.hstack((np.ones((matrix_pop.shape[0], 1)), matrix_pop))\n",
        "predicted_values_pop = matrix_with_intercept_pop @ model_backward_bic_pop.params\n",
        "\n",
        "#tra\n",
        "matrix_tra =  X_all[selected_features_bic].values\n",
        "predicted_values_tra = matrix_tra @ model_backward_bic.params\n",
        "\n",
        "#plot predicted values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(len(predicted_values_pop)), predicted_values_pop, label=\"Predicted (pop)\", color=\"blue\", alpha=0.9)\n",
        "plt.plot(range(len(predicted_values_tra)), predicted_values_tra, label=\"Predicted (tra)\", color=\"orange\", alpha=0.9)\n",
        "plt.plot(range(len(df_cleaned['medv'])), df_cleaned['medv'], label=\"Medv\", color=\"green\", alpha=0.3)\n",
        "\n",
        "plt.xlabel(\"Index\", fontsize=12)\n",
        "plt.ylabel(\"Predicted medv\", fontsize=12)\n",
        "plt.title(\"Scatter Plot of Predicted Values: pop vs tra\", fontsize=14)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "817PZ3nwHFHm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}