{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francji1/01RAD/blob/main/code/01RAD_Ex05_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oWcfAcQiTBV"
      },
      "source": [
        "# 01RAD Exercise 05\n",
        "\n",
        "This notebook explores linear regression inference and diagnostics on the `mpg` dataset. We connect theory (OLS, independence of coefficients and error variance) with practice (bootstrapping, simulation, multicollinearity, residual diagnostics, and multiple testing).\n",
        "\n",
        "Learning objectives:\n",
        "- Understand and interpret OLS output (t-tests, F-test, R², adj. R²).\n",
        "- Explain why $\\hat{\\beta}$ and $s^2$ are independent under the classical assumptions.\n",
        "- Diagnose multicollinearity (VIF) and residual issues (normality, heteroscedasticity, influence).\n",
        "- Compare variable selection approaches and recognize pitfalls (stepwise vs. regularization).\n",
        "- Apply and interpret multiple-comparison corrections (FWER, FDR).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNRvyml509Yi"
      },
      "source": [
        "**Contents**\n",
        "\n",
        "- Setup & Requirements\n",
        "- Data Overview\n",
        "- Exploratory Analysis\n",
        "- Simple OLS: mpg ~ horsepower\n",
        "- Theory: Independence of $\\hat{\\beta}$ and $s^2$\n",
        "- Empirical Check: Bootstrap\n",
        "- Simulation Study\n",
        "- Correlation Demo\n",
        "- F-test vs t-tests\n",
        "- Manual Calculations (SE, t, F)\n",
        "- Multicollinearity & VIF\n",
        "- Residual Diagnostics\n",
        "- Feature Selection (Stepwise, caveats)\n",
        "- Multiple Testing Corrections (FWER, FDR)\n",
        "- Interpretation Summary\n",
        "- Homework\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMd_KRvg09Yi"
      },
      "source": [
        "**Setup & Requirements**\n",
        "\n",
        "- Python packages: `pandas`, `numpy`, `seaborn`, `matplotlib`, `statsmodels`, `scikit-learn`, `scipy`, `mlxtend` (optional for stepwise).\n",
        "- If running locally, install missing packages as needed:\n",
        "\n",
        "```bash\n",
        "pip install pandas numpy seaborn matplotlib statsmodels scikit-learn scipy mlxtend\n",
        "```\n",
        "\n",
        "- Notes:\n",
        "  - You may set a global random seed for reproducibility.\n",
        "  - Consider setting a plotting theme via `seaborn` for consistent visuals.\n",
        "  - Formula API (`statsmodels.formula.api.ols`) vs matrix API (`statsmodels.api.OLS`): we use both for clarity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygUsfOM709Yi"
      },
      "source": [
        "**Feature Selection: Stepwise (Caveats)**\n",
        "\n",
        "Stepwise procedures can be unstable and inflate Type I error. Prefer cross-validation and/or penalized regression (Ridge/LASSO) when prediction is the goal.\n",
        "\n",
        "In inferential settings, pre-specify hypotheses and limit data-driven selection, or adjust for multiplicity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:25.868217Z",
          "iopub.status.busy": "2025-11-04T16:21:25.868217Z",
          "iopub.status.idle": "2025-11-04T16:21:28.043569Z",
          "shell.execute_reply": "2025-11-04T16:21:28.043569Z"
        },
        "id": "m7xJkVkZ09Yi"
      },
      "outputs": [],
      "source": [
        "# Imports: data handling, modeling, plots, and utilities\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.utils import resample\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.graphics.gofplots import ProbPlot\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "from scipy import stats\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "try:\n",
        "    from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "    HAS_MLXTEND = True\n",
        "except ImportError:\n",
        "    HAS_MLXTEND = False\n",
        "\n",
        "# Configure plotting style and reproducibility\n",
        "sns.set_theme(style=\"whitegrid\", context=\"notebook\")\n",
        "pd.set_option(\"display.float_format\", lambda value: f\"{value:,.3f}\")\n",
        "RNG = np.random.default_rng(42)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"statsmodels\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCOfP3rJ09Yj"
      },
      "source": [
        "**Data Overview**\n",
        "\n",
        "We use the classic `mpg` dataset from `seaborn`, containing fuel efficiency and vehicle characteristics. Key variables include:\n",
        "- `mpg`: miles per gallon (response)\n",
        "- `horsepower`, `displacement`, `weight`, `acceleration`: numeric predictors\n",
        "- `origin`: region (categorical), `model_year`, etc.\n",
        "\n",
        "Preprocessing notes:\n",
        "- Remove rows with missing values (done here via `.dropna()`).\n",
        "- Ensure numeric dtype for key predictors (e.g., `horsepower` can be non-numeric in some sources).\n",
        "- Decide upfront whether the goal is inference (explain relationships) or prediction (forecast new `mpg`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:28.045615Z",
          "iopub.status.busy": "2025-11-04T16:21:28.045615Z",
          "iopub.status.idle": "2025-11-04T16:21:28.059202Z",
          "shell.execute_reply": "2025-11-04T16:21:28.059202Z"
        },
        "id": "9jTWMkeyX0K1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the dataset and enforce numeric dtype where needed\n",
        "data = sns.load_dataset(\"mpg\").dropna().copy()\n",
        "\n",
        "# Ensure numeric columns have the expected dtype\n",
        "data.loc[:, \"mpg\"] = data[\"mpg\"].astype(float)\n",
        "data.loc[:, \"horsepower\"] = data[\"horsepower\"].astype(float)\n",
        "data.loc[:, \"origin\"] = data[\"origin\"].astype(\"category\")\n",
        "\n",
        "# Reset the index to keep resampling operations straightforward\n",
        "data.reset_index(drop=True, inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyMEDUyl09Yj"
      },
      "source": [
        "**Exploratory Analysis**\n",
        "\n",
        "- Inspect dtypes and first rows to confirm data integrity.\n",
        "- Explore pairwise relationships (scatterplots) and correlations among predictors.\n",
        "- Look for skewness/outliers and potential non-linear patterns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:28.061203Z",
          "iopub.status.busy": "2025-11-04T16:21:28.061203Z",
          "iopub.status.idle": "2025-11-04T16:21:28.070202Z",
          "shell.execute_reply": "2025-11-04T16:21:28.070202Z"
        },
        "id": "8BuX66hkX9n-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Inspect dtypes to confirm numeric variables for modeling\n",
        "display(data.dtypes.to_frame(name=\"dtype\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:28.103202Z",
          "iopub.status.busy": "2025-11-04T16:21:28.103202Z",
          "iopub.status.idle": "2025-11-04T16:21:28.109840Z",
          "shell.execute_reply": "2025-11-04T16:21:28.109840Z"
        },
        "id": "tJJaQNvNQvDX"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Quick glimpse at the first rows\n",
        "display(data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:28.111877Z",
          "iopub.status.busy": "2025-11-04T16:21:28.111877Z",
          "iopub.status.idle": "2025-11-04T16:21:28.126348Z",
          "shell.execute_reply": "2025-11-04T16:21:28.126348Z"
        },
        "id": "Gilpc_Xl09Yk"
      },
      "outputs": [],
      "source": [
        "# Summaries to understand central tendency and spread\n",
        "print(f\"Dataset shape: {data.shape[0]} rows × {data.shape[1]} columns\")\n",
        "display(data.describe().T)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:28.128387Z",
          "iopub.status.busy": "2025-11-04T16:21:28.128387Z",
          "iopub.status.idle": "2025-11-04T16:21:28.135047Z",
          "shell.execute_reply": "2025-11-04T16:21:28.135047Z"
        },
        "id": "RZA0HAehtxQU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Spot-check a random sample of rows\n",
        "display(data.sample(5, random_state=RNG.integers(0, 10_000)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:28.137054Z",
          "iopub.status.busy": "2025-11-04T16:21:28.137054Z",
          "iopub.status.idle": "2025-11-04T16:21:28.143150Z",
          "shell.execute_reply": "2025-11-04T16:21:28.143150Z"
        },
        "id": "G6i3a4KUs0CF"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Correlations among selected predictors\n",
        "corr_subset = data[[\"displacement\", \"horsepower\", \"weight\", \"acceleration\"]].corr()\n",
        "display(corr_subset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:28.145159Z",
          "iopub.status.busy": "2025-11-04T16:21:28.145159Z",
          "iopub.status.idle": "2025-11-04T16:21:29.393500Z",
          "shell.execute_reply": "2025-11-04T16:21:29.393500Z"
        },
        "id": "v8isbVcd09Yk"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Pairplot to inspect linear relationships and potential non-linearity\n",
        "pairplot_features = [\"mpg\", \"horsepower\", \"weight\", \"displacement\", \"acceleration\"]\n",
        "plot_sample = data[pairplot_features]\n",
        "if len(plot_sample) > 200:\n",
        "    plot_sample = plot_sample.sample(n=200, random_state=RNG.integers(0, 10_000))\n",
        "sns.pairplot(plot_sample, diag_kind=\"kde\", corner=True)\n",
        "plt.suptitle(\"Pairplot of Selected Features\", y=1.02)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:29.395504Z",
          "iopub.status.busy": "2025-11-04T16:21:29.395504Z",
          "iopub.status.idle": "2025-11-04T16:21:29.545755Z",
          "shell.execute_reply": "2025-11-04T16:21:29.545755Z"
        },
        "id": "nOdTCdzk09Yk"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Correlation heatmap to quantify linear association\n",
        "corr = data[[\"mpg\", \"horsepower\", \"weight\", \"displacement\", \"acceleration\"]].corr()\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(corr, annot=True, cmap=\"vlag\", center=0, fmt=\".2f\")\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:29.547759Z",
          "iopub.status.busy": "2025-11-04T16:21:29.547759Z",
          "iopub.status.idle": "2025-11-04T16:21:29.675477Z",
          "shell.execute_reply": "2025-11-04T16:21:29.675477Z"
        },
        "id": "RGLrK48N09Yk"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Distribution of the response variable to check skewness and outliers\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.histplot(data[\"mpg\"], bins=20, kde=True, color=\"#4472C4\")\n",
        "plt.xlabel(\"mpg\")\n",
        "plt.title(\"Distribution of MPG\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0FKwq9N09Yl"
      },
      "source": [
        "**Simple OLS: mpg ~ horsepower**\n",
        "\n",
        "We begin with a simple linear model to build intuition.\n",
        "\n",
        "Interpretation tips:\n",
        "- Coefficient sign and magnitude reflect average linear association (holding nothing else constant).\n",
        "- Check residual plots later for non-linearity or heteroscedasticity.\n",
        "- R² in simple regression equals the squared Pearson correlation between `mpg` and `horsepower`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:29.677486Z",
          "iopub.status.busy": "2025-11-04T16:21:29.677486Z",
          "iopub.status.idle": "2025-11-04T16:21:29.692205Z",
          "shell.execute_reply": "2025-11-04T16:21:29.692205Z"
        },
        "id": "pj7w53XOvsju"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Fit simple OLS: mpg ~ horsepower and review key statistics\n",
        "simple_model = smf.ols(\"mpg ~ horsepower\", data=data).fit()\n",
        "\n",
        "print(f\"R-squared: {simple_model.rsquared:.3f}  (Adjusted: {simple_model.rsquared_adj:.3f})\")\n",
        "pearson_r, pearson_p = pearsonr(data[\"mpg\"], data[\"horsepower\"])\n",
        "print(f\"Pearson r: {pearson_r:.3f}; r^2: {pearson_r**2:.3f}; p-value: {pearson_p:.3g}\")\n",
        "\n",
        "display(simple_model.summary2().tables[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:29.694213Z",
          "iopub.status.busy": "2025-11-04T16:21:29.694213Z",
          "iopub.status.idle": "2025-11-04T16:21:29.920432Z",
          "shell.execute_reply": "2025-11-04T16:21:29.920432Z"
        },
        "id": "Ojr_NeSp09Yl"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Residual diagnostics for the simple model\n",
        "residuals_simple = simple_model.resid\n",
        "fitted_simple = simple_model.fittedvalues\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "sns.scatterplot(x=fitted_simple, y=residuals_simple, ax=axes[0])\n",
        "axes[0].axhline(0, color=\"red\", linestyle=\"--\")\n",
        "axes[0].set_title(\"Residuals vs Fitted\")\n",
        "axes[0].set_xlabel(\"Fitted values\")\n",
        "axes[0].set_ylabel(\"Residuals\")\n",
        "\n",
        "sm.qqplot(residuals_simple, line=\"45\", ax=axes[1])\n",
        "axes[1].set_title(\"Q-Q Plot\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njwV53DTm89b"
      },
      "source": [
        "# Theory: Independence of $\\hat{\\beta}$ and $s^2$\n",
        "\n",
        "Consider the linear model $y = X\\beta + \\varepsilon$, with $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2 I)$. The OLS estimator and residuals are:\n",
        "- $\\hat{\\beta} = (X'X)^{-1}X'y$, so $\\hat{\\beta} \\sim \\mathcal{N}(\\beta, \\sigma^2 (X'X)^{-1})$.\n",
        "- Residuals: $e = y - X\\hat{\\beta} = (I - H)y$, where $H = X(X'X)^{-1}X'$ is the hat matrix.\n",
        "- Error variance estimator: $s^2 = \\mathrm{RSS}/(n - p)$, with $(n-p)s^2/\\sigma^2 \\sim \\chi^2_{n-p}$.\n",
        "\n",
        "Key fact: $X'e = 0$ (orthogonality of fitted and residual components), and under normal errors, $\\hat{\\beta}$ and $e$ are independent.\n",
        "Therefore, $\\hat{\\beta}$ and $s^2$ are independent random variables.\n",
        "\n",
        "Proof sketch with the hat matrix:\n",
        "- Decompose $y$ into orthogonal parts: $Hy$ (in span of $X$) and $(I-H)y$ (in its orthogonal complement).\n",
        "- $\\hat{\\beta}$ depends only on $Hy$; $s^2$ depends only on $(I-H)y$. Under Gaussian errors, these parts are independent.\n",
        "\n",
        "Practical note: Empirically, you may see small sample correlations between estimates and residual variance, but theory predicts independence under the classical assumptions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mMaGWaw09Yl"
      },
      "source": [
        "**Empirical Check: Bootstrap Independence**\n",
        "\n",
        "We resample the observed data with replacement and refit the model many times to obtain empirical distributions of coefficients and $s^2$.\n",
        "\n",
        "Notes:\n",
        "- Bootstrap corroborates the lack of association in this dataset, but strict independence is a theoretical result (under normality).\n",
        "- Use sufficient resamples (e.g., 1000+) for stability, mindful of runtime.\n",
        "- Visualize $s^2$ vs each $\\hat{\\beta}$ (scatter with LOWESS) and summarize with correlation estimates/intervals.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:29.922441Z",
          "iopub.status.busy": "2025-11-04T16:21:29.922441Z",
          "iopub.status.idle": "2025-11-04T16:21:30.537435Z",
          "shell.execute_reply": "2025-11-04T16:21:30.537435Z"
        },
        "id": "4YtkQzsJ09Yl"
      },
      "outputs": [],
      "source": [
        "# Bootstrap loop to empirically examine association between s^2 and coefficients\n",
        "predictors = [\"horsepower\", \"weight\"]\n",
        "X = sm.add_constant(data[predictors])\n",
        "y = data[\"mpg\"]\n",
        "\n",
        "n_bootstraps = 1000\n",
        "beta_estimates = np.empty((n_bootstraps, X.shape[1]))\n",
        "sigma_squared_estimates = np.empty(n_bootstraps)\n",
        "\n",
        "for i in range(n_bootstraps):\n",
        "    sample_idx = RNG.integers(0, len(data), len(data))\n",
        "    X_resampled = X.iloc[sample_idx]\n",
        "    y_resampled = y.iloc[sample_idx]\n",
        "    bootstrap_model = sm.OLS(y_resampled, X_resampled).fit()\n",
        "    beta_estimates[i] = bootstrap_model.params.values\n",
        "    sigma_squared_estimates[i] = bootstrap_model.mse_resid\n",
        "\n",
        "beta_df = pd.DataFrame(beta_estimates, columns=X.columns)\n",
        "beta_df[\"s_n_squared\"] = sigma_squared_estimates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:30.539434Z",
          "iopub.status.busy": "2025-11-04T16:21:30.539434Z",
          "iopub.status.idle": "2025-11-04T16:21:30.549004Z",
          "shell.execute_reply": "2025-11-04T16:21:30.549004Z"
        },
        "id": "zPHICvYEtxS9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Collect bootstrap estimates into a DataFrame for analysis\n",
        "corr_summary = []\n",
        "for col in X.columns:\n",
        "    pearson_r, pearson_p = pearsonr(beta_df[col], beta_df[\"s_n_squared\"])\n",
        "    spearman_r, spearman_p = spearmanr(beta_df[col], beta_df[\"s_n_squared\"])\n",
        "    corr_summary.append(\n",
        "        {\n",
        "            \"parameter\": col,\n",
        "            \"pearson_r\": pearson_r,\n",
        "            \"pearson_p\": pearson_p,\n",
        "            \"spearman_r\": spearman_r,\n",
        "            \"spearman_p\": spearman_p,\n",
        "        }\n",
        "    )\n",
        "\n",
        "corr_summary_df = pd.DataFrame(corr_summary)\n",
        "display(corr_summary_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:30.551002Z",
          "iopub.status.busy": "2025-11-04T16:21:30.551002Z",
          "iopub.status.idle": "2025-11-04T16:21:31.318562Z",
          "shell.execute_reply": "2025-11-04T16:21:31.318562Z"
        },
        "id": "TT5HMwpRvOto"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Visualize relationship between s^2 and each coefficient estimate\n",
        "for col in X.columns:\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.regplot(x=beta_df[\"s_n_squared\"], y=beta_df[col], lowess=True, scatter_kws={\"alpha\": 0.3})\n",
        "    plt.title(f\"s^2 vs {col} (Bootstrap estimates)\")\n",
        "    plt.xlabel(\"s^2 (bootstrap)\")\n",
        "    plt.ylabel(f\"{col} estimate\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:31.320563Z",
          "iopub.status.busy": "2025-11-04T16:21:31.320563Z",
          "iopub.status.idle": "2025-11-04T16:21:31.606869Z",
          "shell.execute_reply": "2025-11-04T16:21:31.606869Z"
        },
        "id": "FhHN5sbuw_2H"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Estimate uncertainty around the correlation via bootstrap resampling\n",
        "n_permutations = 1000\n",
        "correlations = []\n",
        "for _ in range(n_permutations):\n",
        "    s_sample = RNG.choice(beta_df[\"s_n_squared\"], size=len(beta_df), replace=True)\n",
        "    beta_sample = RNG.choice(beta_df[\"const\"], size=len(beta_df), replace=True)\n",
        "    correlations.append(np.corrcoef(s_sample, beta_sample)[0, 1])\n",
        "\n",
        "ci_lower, ci_upper = np.percentile(correlations, [2.5, 97.5])\n",
        "print(f\"Bootstrap correlation 95% CI for const: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.histplot(correlations, bins=30, kde=True, color=\"#70AD47\")\n",
        "plt.axvline(ci_lower, color=\"red\", linestyle=\"--\", label=\"95% CI\")\n",
        "plt.axvline(ci_upper, color=\"red\", linestyle=\"--\")\n",
        "plt.title(\"Bootstrap Distribution of Correlation (const vs s^2)\")\n",
        "plt.xlabel(\"Correlation\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXDyhk_wkQIP"
      },
      "source": [
        "\n",
        "\n",
        "## Simulation Exercise\n",
        "\n",
        "To empirically demonstrate the independence of $\\hat{\\beta}$ and $s_n^2$, we can use simulation.\n",
        "\n",
        "### Task\n",
        "\n",
        "1. **Generate Data**: Simulate data based on a simple linear regression model.\n",
        "   - Set up a design matrix $X$ with an intercept and one or more predictors.\n",
        "   - Generate response values $Y$ based on a known linear relationship with added Gaussian noise.\n",
        "   \n",
        "2. **Estimate $\\hat{\\beta}$ and $s_n^2$**:\n",
        "   - Use OLS to compute $\\hat{\\beta}$ and $s_n^2$ for each simulated dataset.\n",
        "\n",
        "3. **Repeat Simulations**:\n",
        "   - Perform the simulation multiple times (e.g., 1000 times) to generate distributions for $\\hat{\\beta}$ and $s_n^2$.\n",
        "\n",
        "4. **Calculate Correlation**:\n",
        "   - Calculate the correlation between the simulated values of $\\hat{\\beta}$ and $s_n^2$.\n",
        "   - If $\\hat{\\beta}$ and $s_n^2$ are independent, the correlation should be close to zero.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6eQA2fN09Ym"
      },
      "source": [
        "**Simulation Study**\n",
        "\n",
        "We simulate data from a known linear model to study sampling behavior.\n",
        "\n",
        "Design ideas:\n",
        "- Control multicollinearity by making predictors correlated (e.g., `X2 = X1 + noise`).\n",
        "- Compare Pearson and Spearman correlation between $s^2$ and each $\\hat{\\beta}$ across resamples.\n",
        "- Inspect residual diagnostics to verify assumptions used in the theory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:31.608899Z",
          "iopub.status.busy": "2025-11-04T16:21:31.608899Z",
          "iopub.status.idle": "2025-11-04T16:21:32.050992Z",
          "shell.execute_reply": "2025-11-04T16:21:32.050992Z"
        },
        "id": "61cyfNDcyzOt"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Simulated data to study sampling behavior and multicollinearity\n",
        "n_samples = 200\n",
        "X1 = RNG.normal(2, 1, n_samples)\n",
        "X2 = X1 + RNG.normal(0, 0.5, n_samples)\n",
        "X3 = RNG.normal(4, 1, n_samples)\n",
        "intercept = np.ones(n_samples)\n",
        "noise = RNG.normal(0, 1, n_samples)\n",
        "y_sim = 3 + 2 * X1 - 1 * X2 + 5 * X3 + noise\n",
        "\n",
        "X_sim = pd.DataFrame({\"const\": intercept, \"X1\": X1, \"X2\": X2, \"X3\": X3})\n",
        "model_sim = sm.OLS(y_sim, X_sim).fit()\n",
        "\n",
        "n_bootstrap_sim = 1000\n",
        "beta_sim = np.empty((n_bootstrap_sim, X_sim.shape[1]))\n",
        "sigma_sim = np.empty(n_bootstrap_sim)\n",
        "\n",
        "for i in range(n_bootstrap_sim):\n",
        "    idx = RNG.integers(0, n_samples, n_samples)\n",
        "    X_boot = X_sim.iloc[idx]\n",
        "    y_boot = y_sim[idx]\n",
        "    model_boot = sm.OLS(y_boot, X_boot).fit()\n",
        "    beta_sim[i] = model_boot.params.values\n",
        "    sigma_sim[i] = model_boot.mse_resid\n",
        "\n",
        "beta_sim_df = pd.DataFrame(beta_sim, columns=X_sim.columns)\n",
        "beta_sim_df[\"s_n_squared\"] = sigma_sim\n",
        "\n",
        "display(model_sim.summary2().tables[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:32.053034Z",
          "iopub.status.busy": "2025-11-04T16:21:32.053034Z",
          "iopub.status.idle": "2025-11-04T16:21:32.198119Z",
          "shell.execute_reply": "2025-11-04T16:21:32.197513Z"
        },
        "id": "z8wnmkpma5FV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Correlation matrix between coefficients and s^2 in the simulated setting\n",
        "sim_corr = beta_sim_df.corr()\n",
        "display(sim_corr.loc[[\"const\", \"X1\", \"X2\", \"X3\"], [\"s_n_squared\"]])\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(sim_corr, annot=True, cmap=\"crest\", fmt=\".2f\")\n",
        "plt.title(\"Simulation: Correlation Matrix of Bootstrap Estimates\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:32.199086Z",
          "iopub.status.busy": "2025-11-04T16:21:32.199086Z",
          "iopub.status.idle": "2025-11-04T16:21:32.203530Z",
          "shell.execute_reply": "2025-11-04T16:21:32.203530Z"
        },
        "id": "t-8-XFDwGrsA"
      },
      "outputs": [],
      "source": [
        "# Calculate the correlation matrix\n",
        "correlation_matrix = beta_df.corr()\n",
        "print(\"Correlation Matrix between each beta estimate and s_n^2:\")\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tII0cQgA09Yn"
      },
      "source": [
        "**Correlation Demo (Toy Example)**\n",
        "\n",
        "This small example contrasts Pearson (linear) vs Spearman (rank/monotonic) correlation.\n",
        "- Pearson captures linear association;\n",
        "- Spearman is robust to monotonic but non-linear relationships and outliers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:32.205694Z",
          "iopub.status.busy": "2025-11-04T16:21:32.205678Z",
          "iopub.status.idle": "2025-11-04T16:21:32.307406Z",
          "shell.execute_reply": "2025-11-04T16:21:32.307406Z"
        },
        "id": "KBt_umrH5le0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Generate a monotonic but non-linear relationship to compare Pearson vs Spearman correlation\n",
        "x = np.linspace(-3, 3, 200)\n",
        "y = x**2 + RNG.normal(0, 0.5, size=x.size)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.scatterplot(x=x, y=y, alpha=0.6)\n",
        "plt.title(\"Non-linear Monotonic Relationship\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()\n",
        "\n",
        "pearson_r, pearson_p = pearsonr(x, y)\n",
        "spearman_r, spearman_p = spearmanr(x, y)\n",
        "print(f\"Pearson r = {pearson_r:.3f}, p = {pearson_p:.3g}\")\n",
        "print(f\"Spearman rho = {spearman_r:.3f}, p = {spearman_p:.3g}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aSpzaLw09Yn"
      },
      "source": [
        "**Unrelated Predictors and the Global F-test**\n",
        "\n",
        "We add random, unrelated predictors to illustrate that, in expectation, they should not be significant.\n",
        "\n",
        "Theory reminder:\n",
        "- The overall F-test evaluates the joint null that all slopes are zero.\n",
        "- In a single-parameter model, $F = t^2$.\n",
        "- With many predictors, the F-test can reject even if some individual t-tests are not significant (shared variance, collinearity).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:32.309407Z",
          "iopub.status.busy": "2025-11-04T16:21:32.309407Z",
          "iopub.status.idle": "2025-11-04T16:21:32.330414Z",
          "shell.execute_reply": "2025-11-04T16:21:32.330414Z"
        },
        "id": "cqPZ9NSo6HjX"
      },
      "outputs": [],
      "source": [
        "# Add unrelated (random) predictors to test spurious significance\n",
        "for col in [\"random1\", \"random2\", \"random3\"]:\n",
        "    data.loc[:, col] = RNG.normal(0, 1, len(data))\n",
        "\n",
        "random_model = smf.ols(\"mpg ~ random1 + random2 + random3\", data=data).fit()\n",
        "print(\"Random-only model (expect low explanatory power)\")\n",
        "display(random_model.summary2().tables[0])\n",
        "display(random_model.summary2().tables[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:32.332415Z",
          "iopub.status.busy": "2025-11-04T16:21:32.332415Z",
          "iopub.status.idle": "2025-11-04T16:21:33.545661Z",
          "shell.execute_reply": "2025-11-04T16:21:33.545661Z"
        },
        "id": "dHp99QH809Yn"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Estimate false-positive rate when regressing mpg on noise predictors\n",
        "alpha = 0.05\n",
        "n_trials = 200\n",
        "significant_counts = []\n",
        "for _ in range(n_trials):\n",
        "    temp = data.copy()\n",
        "    for col in [\"noise_a\", \"noise_b\", \"noise_c\"]:\n",
        "        temp.loc[:, col] = RNG.normal(0, 1, len(temp))\n",
        "    noise_model = smf.ols(\"mpg ~ noise_a + noise_b + noise_c\", data=temp).fit()\n",
        "    sig = (noise_model.pvalues.drop(\"Intercept\") < alpha).sum()\n",
        "    significant_counts.append(sig)\n",
        "\n",
        "false_positive_rate = np.mean(np.array(significant_counts) > 0)\n",
        "print(f\"Proportion of trials with at least one false positive (alpha={alpha}): {false_positive_rate:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6Y-kbPg09Yn"
      },
      "source": [
        "**Comparing F-test and t-tests**\n",
        "\n",
        "Interpretation tips:\n",
        "- If the global F-test is significant but many t-tests are not, suspect multicollinearity or insufficient power for individual effects.\n",
        "- Compare partial $R^2$ and standardized effects to gauge practical importance.\n",
        "- Avoid p-hacking: pre-register hypotheses or use corrections when testing many predictors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:33.547665Z",
          "iopub.status.busy": "2025-11-04T16:21:33.547665Z",
          "iopub.status.idle": "2025-11-04T16:21:33.551062Z",
          "shell.execute_reply": "2025-11-04T16:21:33.551062Z"
        },
        "id": "XvX5qg4upQq1"
      },
      "outputs": [],
      "source": [
        "# Compare the F-test with individual t-tests for each regression coefficient\n",
        "# F-test p-value (overall model significance)\n",
        "f_test_pvalue = random_model.f_pvalue\n",
        "\n",
        "# Individual t-test p-values\n",
        "t_test_pvalues = random_model.pvalues\n",
        "\n",
        "print(\"\\nF-test p-value (for the entire model):\", f_test_pvalue)\n",
        "print(\"Individual t-test p-values (for each coefficient):\")\n",
        "print(t_test_pvalues)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:33.553067Z",
          "iopub.status.busy": "2025-11-04T16:21:33.552067Z",
          "iopub.status.idle": "2025-11-04T16:21:33.572116Z",
          "shell.execute_reply": "2025-11-04T16:21:33.572116Z"
        },
        "id": "EAS7gBajpV1G"
      },
      "outputs": [],
      "source": [
        "# Combine real and random predictors; examine F-test vs individual t-tests\n",
        "combined_formula = \"mpg ~ random1 + random2 + random3 + horsepower + weight + acceleration\"\n",
        "combined_model = smf.ols(combined_formula, data=data).fit()\n",
        "print(\"Model with both signal and noise variables\")\n",
        "display(combined_model.summary2().tables[1])\n",
        "\n",
        "f_test_pvalue_combined = combined_model.f_pvalue\n",
        "print(f\"Global F-test p-value: {f_test_pvalue_combined:.4g}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:33.574120Z",
          "iopub.status.busy": "2025-11-04T16:21:33.574120Z",
          "iopub.status.idle": "2025-11-04T16:21:33.577951Z",
          "shell.execute_reply": "2025-11-04T16:21:33.577951Z"
        },
        "id": "zsRPGR5IP44A"
      },
      "outputs": [],
      "source": [
        "# Compare the F-test with individual t-tests for each regression coefficient\n",
        "f_test_pvalue_combined = combined_model.f_pvalue\n",
        "t_test_pvalues_combined = combined_model.pvalues\n",
        "\n",
        "print(\"\\nF-test p-value (for the combined model):\", \"{:.4f}\".format(f_test_pvalue_combined) )\n",
        "print(\"Individual t-test p-values (for each coefficient in the combined model):\")\n",
        "t_test_pvalues_combined_formatted = t_test_pvalues_combined.apply(lambda x: f\"{x:.4f}\")\n",
        "print(t_test_pvalues_combined_formatted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:33.579955Z",
          "iopub.status.busy": "2025-11-04T16:21:33.579955Z",
          "iopub.status.idle": "2025-11-04T16:21:33.595252Z",
          "shell.execute_reply": "2025-11-04T16:21:33.595252Z"
        },
        "id": "Zcvkmll-pcKN"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Specify a candidate final model based on significance and interpretability\n",
        "final_model_formula = \"mpg ~ horsepower + weight + acceleration\"\n",
        "final_model = smf.ols(final_model_formula, data=data).fit()\n",
        "print(\"Final model summary\")\n",
        "display(final_model.summary2().tables[1])\n",
        "print(f\"Adjusted R^2: {final_model.rsquared_adj:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:33.597256Z",
          "iopub.status.busy": "2025-11-04T16:21:33.597256Z",
          "iopub.status.idle": "2025-11-04T16:21:33.603615Z",
          "shell.execute_reply": "2025-11-04T16:21:33.603615Z"
        },
        "id": "iIasSde209Yp"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Demonstrate that, for a single predictor, F equals t^2\n",
        "single_model = smf.ols(\"mpg ~ horsepower\", data=data).fit()\n",
        "t_value = single_model.tvalues[\"horsepower\"]\n",
        "f_value = single_model.fvalue\n",
        "print(f\"t^2 = {t_value**2:.4f}, F = {f_value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahrDD46N09Yp"
      },
      "source": [
        "**Manual Calculations: SE, t, and F**\n",
        "\n",
        "Formulas used:\n",
        "- $s = \\sqrt{\\mathrm{RSS}/(n-p)}$\n",
        "- $\\mathrm{Var}(\\hat{\\beta}) = \\sigma^2 (X'X)^{-1}$, so $se(\\hat{\\beta}_i) = s \\sqrt{(X'X)^{-1}_{ii}}$\n",
        "- $t_i = \\hat{\\beta}_i / se(\\hat{\\beta}_i)$ with $\\mathrm{df}=n-p$\n",
        "- Nested-model F-test: $F = \\frac{(RSS_r - RSS_f)/q}{RSS_f/(n - p_f)}$\n",
        "\n",
        "We verify that manual calculations align with `statsmodels` outputs. Small differences are due to rounding.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:33.605622Z",
          "iopub.status.busy": "2025-11-04T16:21:33.605622Z",
          "iopub.status.idle": "2025-11-04T16:21:33.608668Z",
          "shell.execute_reply": "2025-11-04T16:21:33.608668Z"
        },
        "id": "deJxFlJDRkUr"
      },
      "outputs": [],
      "source": [
        "\n",
        "# (X'X)^(-1) used to compute standard errors manually\n",
        "X_design = final_model.model.exog\n",
        "y_obs = final_model.model.endog\n",
        "\n",
        "XtX_inv = np.linalg.inv(X_design.T @ X_design)\n",
        "n_obs, n_params = X_design.shape\n",
        "rss = np.sum(final_model.resid**2)\n",
        "s_hat = np.sqrt(rss / (n_obs - n_params))\n",
        "se_manual = s_hat * np.sqrt(np.diag(XtX_inv))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:33.610674Z",
          "iopub.status.busy": "2025-11-04T16:21:33.610674Z",
          "iopub.status.idle": "2025-11-04T16:21:33.613770Z",
          "shell.execute_reply": "2025-11-04T16:21:33.613770Z"
        },
        "id": "7fghD_d7RANL"
      },
      "outputs": [],
      "source": [
        "# Manually compute t-tests for each regressor and compare with statsmodels\n",
        "# Extract the estimated coefficients, standard errors, and degrees of freedom\n",
        "beta_hat = final_model.params\n",
        "se_beta_hat = final_model.bse\n",
        "degrees_of_freedom = final_model.df_resid\n",
        "print(se_beta_hat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:33.615773Z",
          "iopub.status.busy": "2025-11-04T16:21:33.615773Z",
          "iopub.status.idle": "2025-11-04T16:21:33.624123Z",
          "shell.execute_reply": "2025-11-04T16:21:33.624123Z"
        },
        "id": "9gYQYy8TWR5B"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Manual t statistics and p-values compared to statsmodels\n",
        "params = final_model.params\n",
        "se_sm = final_model.bse\n",
        "\n",
        "t_manual = params / se_manual\n",
        "p_manual = 2 * (1 - stats.t.cdf(np.abs(t_manual), df=final_model.df_resid))\n",
        "\n",
        "comparison_df = pd.DataFrame(\n",
        "    {\n",
        "        \"coef\": params,\n",
        "        \"se_manual\": se_manual,\n",
        "        \"se_sm\": se_sm,\n",
        "        \"t_manual\": t_manual,\n",
        "        \"t_sm\": final_model.tvalues,\n",
        "        \"p_manual\": p_manual,\n",
        "        \"p_sm\": final_model.pvalues,\n",
        "    }\n",
        ")\n",
        "display(comparison_df)\n",
        "\n",
        "np.testing.assert_allclose(se_manual, se_sm, rtol=1e-6, atol=1e-8)\n",
        "np.testing.assert_allclose(t_manual, final_model.tvalues.values, rtol=1e-6, atol=1e-8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:33.626121Z",
          "iopub.status.busy": "2025-11-04T16:21:33.626121Z",
          "iopub.status.idle": "2025-11-04T16:21:33.632909Z",
          "shell.execute_reply": "2025-11-04T16:21:33.632909Z"
        },
        "id": "kB2TfZejRTRE"
      },
      "outputs": [],
      "source": [
        "# Compare with statsmodels' computed t-values and p-values\n",
        "print(\"\\nStatsmodels t-test results:\")\n",
        "print(final_model.summary2().tables[1][['Coef.', 't', 'P>|t|']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:33.634907Z",
          "iopub.status.busy": "2025-11-04T16:21:33.634907Z",
          "iopub.status.idle": "2025-11-04T16:21:33.637724Z",
          "shell.execute_reply": "2025-11-04T16:21:33.637724Z"
        },
        "id": "MQDLlhfpWIkk"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Overall model F-test and interpretation\n",
        "f_statistic = final_model.fvalue\n",
        "f_p_value = final_model.f_pvalue\n",
        "print(f\"F-statistic: {f_statistic:.4f} with p-value {f_p_value:.4g}\")\n",
        "print(\"Interpretation: At least one predictor is associated with mpg at conventional significance levels.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXEB_DGJYAgp"
      },
      "source": [
        "Interpret the overall F-test and the individual t-tests together:\n",
        "- Does the model explain a meaningful portion of variance (adjusted $R^2$)?\n",
        "- Are key predictors significant and practically important (effect sizes, units)?\n",
        "- Could multicollinearity mask individual effects despite a significant F-test?\n",
        "- Do diagnostics support assumptions (normality, homoscedasticity, linearity)?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_H14e0I09Yq"
      },
      "source": [
        "**Multicollinearity & VIF**\n",
        "\n",
        "We artificially create highly correlated predictors to illustrate multicollinearity and compute VIF.\n",
        "\n",
        "Guidelines:\n",
        "- VIF > 5 suggests moderate collinearity; VIF > 10 is often considered high.\n",
        "- High VIF inflates standard errors and destabilizes coefficient estimates.\n",
        "- Consider dropping/recombining variables, or applying regularization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:33.639723Z",
          "iopub.status.busy": "2025-11-04T16:21:33.639723Z",
          "iopub.status.idle": "2025-11-04T16:21:33.665350Z",
          "shell.execute_reply": "2025-11-04T16:21:33.665350Z"
        },
        "id": "WFLKl9qrX5OZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create near-duplicates to illustrate multicollinearity\n",
        "data[\"horsepower_noise\"] = data[\"horsepower\"] + RNG.normal(0, 0.1, len(data))\n",
        "data[\"weight_noise\"] = data[\"weight\"] + RNG.normal(0, 0.1, len(data))\n",
        "\n",
        "model_with_noise = smf.ols(\n",
        "    \"mpg ~ horsepower + weight + displacement + horsepower_noise + weight_noise\",\n",
        "    data=data,\n",
        ").fit()\n",
        "print(\"Model including highly correlated predictors\")\n",
        "display(model_with_noise.summary2().tables[0])\n",
        "display(model_with_noise.summary2().tables[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:33.667357Z",
          "iopub.status.busy": "2025-11-04T16:21:33.667357Z",
          "iopub.status.idle": "2025-11-04T16:21:33.806980Z",
          "shell.execute_reply": "2025-11-04T16:21:33.806980Z"
        },
        "id": "SITz4NJUY-9u"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compute Variance Inflation Factor (VIF) to quantify multicollinearity\n",
        "vif_features = [\"horsepower\", \"weight\", \"displacement\", \"horsepower_noise\", \"weight_noise\"]\n",
        "X_vif = sm.add_constant(data[vif_features])\n",
        "vif_values = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]\n",
        "vif_df = pd.DataFrame({\"variable\": X_vif.columns, \"VIF\": vif_values})\n",
        "display(vif_df)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.barplot(\n",
        "    data=vif_df[vif_df[\"variable\"] != \"const\"],\n",
        "    x=\"VIF\",\n",
        "    y=\"variable\",\n",
        "    orient=\"h\",\n",
        "    palette=\"Reds_r\",\n",
        ")\n",
        "plt.axvline(5, color=\"orange\", linestyle=\"--\", label=\"VIF=5\")\n",
        "plt.axvline(10, color=\"red\", linestyle=\"--\", label=\"VIF=10\")\n",
        "plt.title(\"Variance Inflation Factors\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:33.808987Z",
          "iopub.status.busy": "2025-11-04T16:21:33.808987Z",
          "iopub.status.idle": "2025-11-04T16:21:33.832268Z",
          "shell.execute_reply": "2025-11-04T16:21:33.832268Z"
        },
        "id": "aKJa_6xh09Yr"
      },
      "outputs": [],
      "source": [
        "# Create near-duplicates to illustrate multicollinearity\n",
        "data[\"horsepower_noise\"] = data[\"horsepower\"] + RNG.normal(0, 0.1, len(data))\n",
        "data[\"weight_noise\"] = data[\"weight\"] + RNG.normal(0, 0.1, len(data))\n",
        "\n",
        "model_with_noise = smf.ols(\n",
        "    \"mpg ~ horsepower + weight + displacement + horsepower_noise + weight_noise\",\n",
        "    data=data,\n",
        ").fit()\n",
        "print(\"Model including highly correlated predictors\")\n",
        "display(model_with_noise.summary2().tables[0])\n",
        "display(model_with_noise.summary2().tables[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3uJVQrn09Ys"
      },
      "source": [
        "**Residual Diagnostics**\n",
        "\n",
        "We assess OLS assumptions via diagnostic plots. Look for:\n",
        "- Normality (histogram, Q-Q plot).\n",
        "- Homoscedasticity (residuals vs fitted/predictors).\n",
        "- Influence (Cook’s distance, leverage).\n",
        "- Linearity (partial regression plots).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:33.834300Z",
          "iopub.status.busy": "2025-11-04T16:21:33.834300Z",
          "iopub.status.idle": "2025-11-04T16:21:34.076910Z",
          "shell.execute_reply": "2025-11-04T16:21:34.076910Z"
        },
        "id": "Lctt6jARpvu4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Residual diagnostics: normality, variance, and patterns\n",
        "residuals = final_model.resid\n",
        "fitted_values = final_model.fittedvalues\n",
        "studentized_residuals = final_model.get_influence().resid_studentized_internal\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "sns.histplot(residuals, bins=20, ax=axes[0], edgecolor=\"black\")\n",
        "axes[0].set_title(\"Histogram of Residuals\")\n",
        "axes[0].set_xlabel(\"Residual\")\n",
        "axes[0].set_ylabel(\"Frequency\")\n",
        "\n",
        "sm.qqplot(studentized_residuals, line=\"45\", ax=axes[1])\n",
        "axes[1].set_title(\"Q-Q Plot of Studentized Residuals\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:34.078946Z",
          "iopub.status.busy": "2025-11-04T16:21:34.078946Z",
          "iopub.status.idle": "2025-11-04T16:21:34.191291Z",
          "shell.execute_reply": "2025-11-04T16:21:34.191291Z"
        },
        "id": "VffMGjcDp1Cu"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Scale-location plot (spread-location) to assess homoscedasticity\n",
        "sqrt_abs = np.sqrt(np.abs(studentized_residuals))\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.scatterplot(x=fitted_values, y=sqrt_abs, alpha=0.6)\n",
        "plt.axhline(sqrt_abs.mean(), color=\"red\", linestyle=\"--\")\n",
        "plt.xlabel(\"Fitted values\")\n",
        "plt.ylabel(\"sqrt(|Studentized residuals|)\")\n",
        "plt.title(\"Scale-Location Plot\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:34.193294Z",
          "iopub.status.busy": "2025-11-04T16:21:34.193294Z",
          "iopub.status.idle": "2025-11-04T16:21:34.296792Z",
          "shell.execute_reply": "2025-11-04T16:21:34.296792Z"
        },
        "id": "9_SzCY3Cp27k"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Studentized residuals vs. fitted values to check for heteroscedasticity\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.scatterplot(x=fitted_values, y=studentized_residuals, alpha=0.6)\n",
        "plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
        "plt.xlabel(\"Fitted values\")\n",
        "plt.ylabel(\"Studentized residuals\")\n",
        "plt.title(\"Studentized Residuals vs Fitted Values\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:34.298797Z",
          "iopub.status.busy": "2025-11-04T16:21:34.298797Z",
          "iopub.status.idle": "2025-11-04T16:21:34.425136Z",
          "shell.execute_reply": "2025-11-04T16:21:34.425136Z"
        },
        "id": "PkxIYVjno3cs"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Residuals vs. fitted values with LOWESS smoothing\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "sns.residplot(x=fitted_values, y=residuals, lowess=True, color=\"#4472C4\", ax=ax)\n",
        "ax.axhline(0, color=\"red\", linestyle=\"--\")\n",
        "ax.set_title(\"Residuals vs Fitted (LOWESS)\")\n",
        "ax.set_xlabel(\"Fitted values\")\n",
        "ax.set_ylabel(\"Residuals\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:34.427172Z",
          "iopub.status.busy": "2025-11-04T16:21:34.427172Z",
          "iopub.status.idle": "2025-11-04T16:21:34.844580Z",
          "shell.execute_reply": "2025-11-04T16:21:34.844580Z"
        },
        "id": "Zd773OOfp2ZR"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Studentized residuals vs. each predictor to check for non-linearity\n",
        "for predictor in final_model_formula.split(\"~\")[1].split(\"+\"):\n",
        "    predictor = predictor.strip()\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.scatterplot(x=data[predictor], y=studentized_residuals, alpha=0.6)\n",
        "    plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
        "    plt.xlabel(predictor)\n",
        "    plt.ylabel(\"Studentized residuals\")\n",
        "    plt.title(f\"Studentized Residuals vs. {predictor}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:34.846580Z",
          "iopub.status.busy": "2025-11-04T16:21:34.846580Z",
          "iopub.status.idle": "2025-11-04T16:21:35.843261Z",
          "shell.execute_reply": "2025-11-04T16:21:35.842260Z"
        },
        "id": "KyDIxZjuqOGO"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Additional regression diagnostic plots per predictor\n",
        "for predictor in [name.strip() for name in final_model_formula.split(\"~\")[1].split(\"+\")]:\n",
        "    fig = sm.graphics.plot_regress_exog(final_model, predictor)\n",
        "    fig.suptitle(f\"Regression Diagnostics for {predictor}\", y=1.02)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:35.844289Z",
          "iopub.status.busy": "2025-11-04T16:21:35.844289Z",
          "iopub.status.idle": "2025-11-04T16:21:36.142461Z",
          "shell.execute_reply": "2025-11-04T16:21:36.142461Z"
        },
        "id": "TRVXVe2h09Yu"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Influence diagnostics to identify high-leverage or influential observations\n",
        "influence = final_model.get_influence()\n",
        "cooks_d = influence.cooks_distance[0]\n",
        "leverage = influence.hat_matrix_diag\n",
        "\n",
        "influence_df = pd.DataFrame(\n",
        "    {\n",
        "        \"index\": data.index,\n",
        "        \"cooks_distance\": cooks_d,\n",
        "        \"leverage\": leverage,\n",
        "    }\n",
        ").sort_values(\"cooks_distance\", ascending=False).head(5)\n",
        "display(influence_df)\n",
        "\n",
        "sm.graphics.influence_plot(final_model, criterion=\"cooks\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:36.144463Z",
          "iopub.status.busy": "2025-11-04T16:21:36.144463Z",
          "iopub.status.idle": "2025-11-04T16:21:36.364613Z",
          "shell.execute_reply": "2025-11-04T16:21:36.364613Z"
        },
        "id": "_mwn34SD09Yu"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Partial regression plots to assess each predictor's contribution\n",
        "fig = sm.graphics.plot_partregress_grid(final_model)\n",
        "fig.suptitle(\"Partial Regression Plots\", y=1.02)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:36.366576Z",
          "iopub.status.busy": "2025-11-04T16:21:36.366576Z",
          "iopub.status.idle": "2025-11-04T16:21:36.376086Z",
          "shell.execute_reply": "2025-11-04T16:21:36.376086Z"
        },
        "id": "n4QCBxlZbQMy"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:36.378086Z",
          "iopub.status.busy": "2025-11-04T16:21:36.378086Z",
          "iopub.status.idle": "2025-11-04T16:21:36.391403Z",
          "shell.execute_reply": "2025-11-04T16:21:36.391403Z"
        },
        "id": "qpi0YvPvLz9i"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Examine multicollinearity via correlation matrix and remove highly correlated predictors\n",
        "corr_matrix = data.corr(numeric_only=True).abs()\n",
        "display(corr_matrix)\n",
        "\n",
        "corr_threshold = 0.9\n",
        "high_corr_pairs = [\n",
        "    (corr_matrix.index[i], corr_matrix.columns[j])\n",
        "    for i in range(corr_matrix.shape[0])\n",
        "    for j in range(i + 1, corr_matrix.shape[1])\n",
        "    if corr_matrix.iloc[i, j] > corr_threshold and corr_matrix.index[i] != \"mpg\"\n",
        "]\n",
        "\n",
        "print(f\"Highly correlated pairs (threshold > {corr_threshold}): {high_corr_pairs}\")\n",
        "\n",
        "data_reduced = data.drop(columns={pair[0] for pair in high_corr_pairs if pair[0] in data.columns})\n",
        "print(f\"Remaining predictors after dropping columns: {sorted(data_reduced.columns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:36.393401Z",
          "iopub.status.busy": "2025-11-04T16:21:36.393401Z",
          "iopub.status.idle": "2025-11-04T16:21:37.636424Z",
          "shell.execute_reply": "2025-11-04T16:21:37.636424Z"
        },
        "id": "xvNuUnA1Sk_K"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Stepwise selection using mlxtend's SequentialFeatureSelector\n",
        "if HAS_MLXTEND:\n",
        "    y_mtx = data[\"mpg\"]\n",
        "    X_mtx = data.drop(columns=[\"mpg\"])\n",
        "    numeric_cols = X_mtx.select_dtypes(include=[np.number]).columns\n",
        "    X_mtx = X_mtx[numeric_cols]\n",
        "\n",
        "    sfs = SFS(\n",
        "        LinearRegression(),\n",
        "        k_features=\"best\",\n",
        "        forward=True,\n",
        "        floating=True,\n",
        "        scoring=\"r2\",\n",
        "        cv=5,\n",
        "        n_jobs=1,\n",
        "    )\n",
        "    sfs = sfs.fit(X_mtx, y_mtx)\n",
        "    selected_features = list(sfs.k_feature_names_)\n",
        "    formula_mlxtend = \"mpg ~ \" + \" + \".join(selected_features)\n",
        "    model_mlxtend = smf.ols(formula=formula_mlxtend, data=data).fit()\n",
        "    print(f\"Selected features (mlxtend): {selected_features}\")\n",
        "    display(model_mlxtend.summary2().tables[1])\n",
        "else:\n",
        "    print(\"mlxtend is not installed. Install mlxtend to run the stepwise selection demo.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:37.638422Z",
          "iopub.status.busy": "2025-11-04T16:21:37.638422Z",
          "iopub.status.idle": "2025-11-04T16:21:37.924091Z",
          "shell.execute_reply": "2025-11-04T16:21:37.924091Z"
        },
        "id": "L1sQ0p2A09Yu"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Regularized alternatives (Ridge and LASSO) for comparison\n",
        "numeric_predictors = data.drop(columns=[\"mpg\"]).select_dtypes(include=[np.number]).columns\n",
        "X_numeric = data[numeric_predictors].to_numpy()\n",
        "y_numeric = data[\"mpg\"].to_numpy()\n",
        "\n",
        "ridge_model = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"ridge\", RidgeCV(alphas=np.logspace(-3, 3, 50), cv=KFold(n_splits=5, shuffle=True, random_state=42))),\n",
        "    ]\n",
        ")\n",
        "ridge_model.fit(X_numeric, y_numeric)\n",
        "\n",
        "lasso_model = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"lasso\", LassoCV(alphas=np.logspace(-3, 3, 100), cv=KFold(n_splits=5, shuffle=True, random_state=42), max_iter=10_000)),\n",
        "    ]\n",
        ")\n",
        "lasso_model.fit(X_numeric, y_numeric)\n",
        "\n",
        "ridge_coef = pd.Series(ridge_model.named_steps[\"ridge\"].coef_, index=numeric_predictors, name=\"Ridge\")\n",
        "lasso_coef = pd.Series(lasso_model.named_steps[\"lasso\"].coef_, index=numeric_predictors, name=\"LASSO\")\n",
        "\n",
        "coef_df = pd.concat([ridge_coef, lasso_coef], axis=1)\n",
        "display(coef_df)\n",
        "\n",
        "print(f\"Ridge CV R^2: {ridge_model.score(X_numeric, y_numeric):.3f}\")\n",
        "print(f\"LASSO CV R^2 (on training data): {lasso_model.score(X_numeric, y_numeric):.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:37.926089Z",
          "iopub.status.busy": "2025-11-04T16:21:37.926089Z",
          "iopub.status.idle": "2025-11-04T16:21:38.017568Z",
          "shell.execute_reply": "2025-11-04T16:21:38.017568Z"
        },
        "id": "Ze2zdnszcX-v"
      },
      "outputs": [],
      "source": [
        "# Manual backward elimination based on p-values from the t-test\n",
        "def backward_elimination(data, response, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Perform backward elimination using t-test p-values.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : pandas.DataFrame\n",
        "        Dataset including response and predictors.\n",
        "    response : str\n",
        "        Name of the response variable column.\n",
        "    alpha : float, default=0.05\n",
        "        Significance threshold for retaining predictors.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    statsmodels.regression.linear_model.RegressionResultsWrapper\n",
        "        Fitted model after removing predictors with p-values > alpha.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - This is a data-driven procedure and can inflate Type I error.\n",
        "    - Consider cross-validation or penalized regression for prediction tasks.\n",
        "    \"\"\"\n",
        "    numeric_predictors = [\n",
        "        col for col in data.columns if col != response and pd.api.types.is_numeric_dtype(data[col])\n",
        "    ]\n",
        "    predictors = numeric_predictors.copy()\n",
        "    if not predictors:\n",
        "        raise ValueError(\"No numeric predictors available for backward elimination.\")\n",
        "    formula = f\"{response} ~ \" + \" + \".join(predictors)\n",
        "    model = smf.ols(formula=formula, data=data).fit()\n",
        "\n",
        "    while True:\n",
        "        p_values = model.pvalues.drop('Intercept', errors='ignore')\n",
        "        if p_values.empty:\n",
        "            break\n",
        "        max_p_value = p_values.max()\n",
        "\n",
        "        if max_p_value < alpha:\n",
        "            break\n",
        "\n",
        "        max_p_variable = p_values.idxmax()\n",
        "        if max_p_variable not in predictors:\n",
        "            break\n",
        "\n",
        "        print(\n",
        "            f\"Removing '{max_p_variable}' with p-value {max_p_value:.4f} \"\n",
        "            f\"because it is above the alpha threshold of {alpha}\"\n",
        "        )\n",
        "\n",
        "        predictors.remove(max_p_variable)\n",
        "        formula = f\"{response} ~ \" + \" + \".join(predictors) if predictors else f\"{response} ~ 1\"\n",
        "        model = smf.ols(formula=formula, data=data).fit()\n",
        "\n",
        "    return model\n",
        "\n",
        "# Run backward elimination and print summary\n",
        "manual_model = backward_elimination(data.copy(), 'mpg')\n",
        "print(\"Manual Backward Elimination Model Summary:\")\n",
        "print(manual_model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:38.019568Z",
          "iopub.status.busy": "2025-11-04T16:21:38.019568Z",
          "iopub.status.idle": "2025-11-04T16:21:38.345135Z",
          "shell.execute_reply": "2025-11-04T16:21:38.345135Z"
        },
        "id": "TR9i_RB7cXTC"
      },
      "outputs": [],
      "source": [
        "# Multiple-testing corrections: Bonferroni, Holm, Benjamini–Hochberg\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "\n",
        "manual_model = backward_elimination(data.copy(), \"mpg\")\n",
        "f_statistic = manual_model.fvalue\n",
        "f_p_value = manual_model.f_pvalue\n",
        "print(f\"Overall F-statistic: {f_statistic:.4f}, p-value: {f_p_value:.4g}\")\n",
        "\n",
        "individual_pvalues = manual_model.pvalues.drop(\"Intercept\", errors=\"ignore\")\n",
        "\n",
        "corrections = {\n",
        "    \"bonferroni\": multipletests(individual_pvalues, alpha=0.05, method=\"bonferroni\"),\n",
        "    \"holm\": multipletests(individual_pvalues, alpha=0.05, method=\"holm\"),\n",
        "    \"fdr_bh\": multipletests(individual_pvalues, alpha=0.05, method=\"fdr_bh\"),\n",
        "}\n",
        "\n",
        "summary_rows = []\n",
        "for var, p in individual_pvalues.items():\n",
        "    idx = individual_pvalues.index.get_loc(var)\n",
        "    summary_rows.append(\n",
        "        {\n",
        "            \"predictor\": var,\n",
        "            \"p_original\": p,\n",
        "            \"p_bonferroni\": corrections[\"bonferroni\"][1][idx],\n",
        "            \"sig_bonferroni\": corrections[\"bonferroni\"][0][idx],\n",
        "            \"p_holm\": corrections[\"holm\"][1][idx],\n",
        "            \"sig_holm\": corrections[\"holm\"][0][idx],\n",
        "            \"p_fdr_bh\": corrections[\"fdr_bh\"][1][idx],\n",
        "            \"sig_fdr_bh\": corrections[\"fdr_bh\"][0][idx],\n",
        "        }\n",
        "    )\n",
        "\n",
        "corrections_df = pd.DataFrame(summary_rows)\n",
        "display(corrections_df)\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plot_df = corrections_df.melt(\n",
        "    id_vars=\"predictor\",\n",
        "    value_vars=[\"p_original\", \"p_bonferroni\", \"p_holm\", \"p_fdr_bh\"],\n",
        "    var_name=\"method\",\n",
        "    value_name=\"p_value\",\n",
        ")\n",
        "sns.barplot(data=plot_df, x=\"predictor\", y=\"p_value\", hue=\"method\")\n",
        "plt.axhline(0.05, color=\"red\", linestyle=\"--\", label=\"alpha=0.05\")\n",
        "plt.title(\"Original vs Corrected p-values\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-04T16:21:38.347135Z",
          "iopub.status.busy": "2025-11-04T16:21:38.347135Z",
          "iopub.status.idle": "2025-11-04T16:21:38.352141Z",
          "shell.execute_reply": "2025-11-04T16:21:38.352141Z"
        },
        "id": "76aw8wph09Yv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Summary of key findings\n",
        "summary_items = [\n",
        "    f\"Final model adjusted R^2: {final_model.rsquared_adj:.3f}\",\n",
        "    f\"Significant predictors (alpha=0.05): {[pred for pred, p in final_model.pvalues.items() if p < 0.05 and pred != 'Intercept']}\",\n",
        "    f\"Maximum VIF after removing noisy duplicates: {vif_df.loc[vif_df['variable'] != 'const', 'VIF'].astype(float).max():.2f}\",\n",
        "    f\"Number of influential observations (Cook's D > 4/n): {(cooks_d > (4 / len(data))).sum()}\",\n",
        "]\n",
        "for item in summary_items:\n",
        "    print(f\"- {item}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FnSYsL4dFUo"
      },
      "source": [
        "### Conclusion Guidance\n",
        "\n",
        "Summarize findings in plain language:\n",
        "- Which predictors matter, and how (sign and magnitude)?\n",
        "- Does the model meet assumptions? If not, what remedies are appropriate?\n",
        "- How sensitive are conclusions to multicollinearity and multiple testing corrections?\n",
        "- What is the out-of-sample performance expectation?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyjUhZAUgSe5"
      },
      "source": [
        "### Individual Student Work — HW\n",
        "\n",
        "1. Data Exploration and Preprocessing\n",
        "   - Load the `mpg` dataset; keep relevant variables.\n",
        "   - For this HW, use `weight` as the response variable (explicit change).\n",
        "   - Convert `origin` to a categorical variable with three levels (USA, Europe, Japan).\n",
        "   - Plot relationships between `weight` and each predictor, including grouped plots by `origin`.\n",
        "\n",
        "2. Initial Model Fitting\n",
        "   - Fit OLS: `weight ~ horsepower + displacement + acceleration + C(origin)`.\n",
        "   - Interpret coefficients and p-values in context (units, direction, practical magnitude).\n",
        "\n",
        "3. Overall F-test vs Individual t-tests\n",
        "   - Report the global F-test and compare with individual t-tests.\n",
        "   - Compare $R^2$ with adjusted $R^2$ and explain the difference.\n",
        "\n",
        "4. Investigate Correlation\n",
        "   - Identify the two most correlated predictors; remove one and refit.\n",
        "   - Compare the lighter model to the full model (adjusted $R^2$, AIC/BIC).\n",
        "   - At fixed values of common predictors (3 settings), vary the removed predictor randomly and compare prediction intervals across models.\n",
        "\n",
        "5. Categorical Interactions\n",
        "   - Fit a model with interactions: e.g., `weight ~ displacement * C(origin)` or `horsepower * C(origin)`.\n",
        "   - Interpret interaction terms and discuss how `origin` moderates effects.\n",
        "\n",
        "6. Model Selection\n",
        "   - Perform stepwise regression (forward or backward) or compare with LASSO/Ridge (if available).\n",
        "   - Compare final vs initial models in adjusted $R^2$ and AIC; discuss trade-offs.\n",
        "\n",
        "7. Diagnostics\n",
        "   - Produce residual plots and a Q–Q plot. Comment on normality, homoscedasticity, and any influential points.\n",
        "\n",
        "Deliverables: concise narrative (max 1–2 pages) with annotated plots and key tables.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}