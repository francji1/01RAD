{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francji1/01RAD/blob/main/code/01RAD_ex02_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjGmDby1nk4P"
      },
      "source": [
        "# 01RAD Exercise 02"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAE0bYt2XHmJ"
      },
      "source": [
        "# Data exploration\n",
        "\n",
        "Data exploration is essential for understanding the characteristics and relationships in the dataset before fitting any models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d18b99d"
      },
      "source": [
        "\n",
        "This notebook continues the exploratory analysis of the `mpg` dataset. We summarise the variables, compare fuel efficiency across regions, and revisit linear regression building blocks as preparation for the next lecture.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-F1k7Fqn6m8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Core scientific stack and statistical helpers\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "from statsmodels.datasets import get_rdataset\n",
        "from scipy.stats import t, norm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8Axwgkqn8oB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-sDRXemnv9G"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the MPG dataset from seaborn and drop rows with missing values for a clean baseline\n",
        "cars = sns.load_dataset('mpg').dropna()\n",
        "\n",
        "# Peek at the first rows to confirm structure\n",
        "print(cars.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba21d5f4"
      },
      "source": [
        "\n",
        "### Dataset overview\n",
        "We begin by inspecting dataset dimensions and data types to understand what variables are available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78f13d20"
      },
      "outputs": [],
      "source": [
        "\n",
        "# print data summary with number of rows, columns, and missing cells\n",
        "dataset_summary = {\n",
        "    'rows': len(cars),\n",
        "    'columns': cars.shape[1],\n",
        "    'missing_cells': int(cars.isna().sum().sum())\n",
        "}\n",
        "print(dataset_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "541f091e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# print dtypes sorted by column name\n",
        "print(cars.dtypes.sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coA3jc2Gn6wH"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Additional preview\n",
        "print(cars.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-wcSLPnofDR"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Full descriptive statistics across numeric and categorical columns\n",
        "print(cars.describe(include='all'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yonnp3aNo6UG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ef83aa2"
      },
      "source": [
        "\n",
        "### Correlation structure among numeric features\n",
        "Correlations identify which variables move together and highlight potential multicollinearity for later modelling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvXXBiGJoBI8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Select only numeric columns for correlation analysis\n",
        "numeric_cars = cars.select_dtypes(include=[float, int])\n",
        "\n",
        "# Compute the Pearson correlation matrix\n",
        "corr_matrix = numeric_cars.corr()\n",
        "\n",
        "# Visualise the correlations using a heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', vmin=-1, vmax=1)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4_2ndOuo9GS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dee62a6"
      },
      "source": [
        "\n",
        "### Pairwise relationships\n",
        "Pair plots reveal non-linear patterns and potential outliers across combinations of numeric variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Kuu9OTRo9JM"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Generate pairwise scatter plots and kernel density estimates\n",
        "sns.pairplot(numeric_cars)\n",
        "plt.suptitle('Pair Plot for Cars Dataset', y=1.02)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8m-0Atho9lj"
      },
      "source": [
        "Choose mpg as response and weight as regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3cb6bb1"
      },
      "source": [
        "\n",
        "### Focus on MPG and weight\n",
        "Weight is a prime candidate regressor for fuel efficiency. We examine marginal distributions and their relationship.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoIEtya5pDna"
      },
      "outputs": [],
      "source": [
        "# Set up the plot grid with 3 subplots\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# 1. Scatter plot of MPG vs Weight\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.scatterplot(data=cars, x='weight', y='mpg')\n",
        "plt.title(\"Scatter plot of Weight vs MPG\")\n",
        "plt.xlabel(\"Weight\")\n",
        "plt.ylabel(\"MPG\")\n",
        "\n",
        "# 2. Histogram and Density Plot of Weight\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.histplot(cars['weight'], kde=True, color='green', label='Weight')\n",
        "plt.legend()\n",
        "plt.title(\"Histogram and Density Plot of Weight\")\n",
        "plt.xlabel(\"Weight\")\n",
        "\n",
        "# 3. Histogram and Density Plot of MPG\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.histplot(cars['mpg'], kde=True, color='blue', label='MPG')\n",
        "plt.legend()\n",
        "plt.title(\"Histogram and Density Plot of MPG\")\n",
        "plt.xlabel(\"MPG\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bu6Xa0UUpPrG"
      },
      "outputs": [],
      "source": [
        "# Scatter plot of Weight vs MPG with colors by Country (origin)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=cars, x='weight', y='mpg', hue='origin', palette='Set1')\n",
        "\n",
        "# Add labels and title\n",
        "plt.title(\"Scatter plot of Weight vs MPG (Colored by Country)\")\n",
        "plt.xlabel(\"Weight\")\n",
        "plt.ylabel(\"MPG\")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1273854b"
      },
      "source": [
        "\n",
        "### Mean MPG by origin\n",
        "Simple group summaries help motivate formal hypothesis tests.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VbDkYaKqGlA"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compute mean MPG per region and compare differences\n",
        "mean_mpg_by_country = cars.groupby('origin')['mpg'].mean()\n",
        "print('Mean MPG by Country (Origin):')\n",
        "print(mean_mpg_by_country)\n",
        "\n",
        "# Calculate pairwise differences between regional means\n",
        "import itertools\n",
        "country_pairs = list(itertools.combinations(mean_mpg_by_country.index, 2))\n",
        "\n",
        "print('Differences between mean MPG by country pairs:')\n",
        "for country1, country2 in country_pairs:\n",
        "    mean_diff = mean_mpg_by_country[country1] - mean_mpg_by_country[country2]\n",
        "    print(f'Difference between {country1} and {country2}: {mean_diff:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b9ae6b9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# print summary statistics for MPG by origin using groupby\n",
        "mpg_by_origin = cars.groupby('origin')['mpg'].agg(['mean', 'median', 'std', 'count'])\n",
        "print(mpg_by_origin)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b435fd8"
      },
      "source": [
        "\n",
        "### Two-sample t-tests across regions\n",
        "We test whether mean MPG differs across each pair of regions without assuming equal sample sizes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khyyMDofqhb2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Loop over unique pairs of regions and conduct independent-sample t-tests\n",
        "country_list = cars['origin'].unique()\n",
        "\n",
        "for i, country1 in enumerate(country_list):\n",
        "    for country2 in country_list[i + 1:]:\n",
        "        mpg1 = cars[cars['origin'] == country1]['mpg']\n",
        "        mpg2 = cars[cars['origin'] == country2]['mpg']\n",
        "        t_stat, p_value = stats.ttest_ind(mpg1, mpg2)\n",
        "        print(f'T-test between {country1} and {country2}:')\n",
        "        print(f't-statistic: {t_stat:.4f}, p-value: {p_value:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da807d8d"
      },
      "source": [
        "\n",
        "### One-way ANOVA\n",
        "We verify the global null hypothesis that all regional means are equal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaAkiD6xqn_2"
      },
      "outputs": [],
      "source": [
        "# Perform ANOVA to compare means across all countries\n",
        "model = smf.ols('mpg ~ C(origin)', data=cars).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "print(\"\\nANOVA Table:\")\n",
        "print(anova_table)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4ab71a0"
      },
      "source": [
        "\n",
        "### One-way ANOVA via SciPy\n",
        "A direct call to `scipy.stats.f_oneway` reaches the same conclusion as the regression-based ANOVA table.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHPKEnhZqzGl"
      },
      "outputs": [],
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Separate MPG data by country\n",
        "mpg_usa = cars[cars['origin'] == 'usa']['mpg']\n",
        "mpg_japan = cars[cars['origin'] == 'japan']['mpg']\n",
        "mpg_europe = cars[cars['origin'] == 'europe']['mpg']\n",
        "\n",
        "# Perform ANOVA\n",
        "f_stat, p_value = stats.f_oneway(mpg_usa, mpg_japan, mpg_europe)\n",
        "\n",
        "print(f\"ANOVA Results: F-statistic = {f_stat:.4f}, p-value = {p_value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b48ef375"
      },
      "source": [
        "\n",
        "### Tukey HSD post-hoc comparison\n",
        "Once the global null is rejected, Tukey's test highlights which pairs differ.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWgYG9s8qt9r"
      },
      "outputs": [],
      "source": [
        "# Perform Tukey's HSD test for pairwise comparison\n",
        "tukey = pairwise_tukeyhsd(endog=cars['mpg'], groups=cars['origin'], alpha=0.05)\n",
        "print(\"\\nTukey's HSD Test:\")\n",
        "print(tukey.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNI2LwPUqGnu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8neeH4N_qGqc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxAQkuoBqGtH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjzw27vvoAXJ"
      },
      "outputs": [],
      "source": [
        "# 1. Simple Linear Regression: MPG ~ weight\n",
        "model = smf.ols('mpg ~ weight', data=cars)\n",
        "fit = model.fit()\n",
        "print(fit.summary())\n",
        "\n",
        "# Plotting the regression line\n",
        "sns.regplot(x='weight', y='mpg', data=cars, ci=None, line_kws={\"color\": \"red\"})\n",
        "plt.title('MPG vs Weight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "46.2165 / 0.799"
      ],
      "metadata": {
        "id": "dz0miMKBnYQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXeV0-GA2Bxl"
      },
      "source": [
        "### Questions:\n",
        "\n",
        "\n",
        "- What is the difference between **Mean Squared Error (MSE)** and $\\hat{\\sigma}^2 $ in the context of linear regression?\n",
        "  - Why is MSE sometimes defined as $\\frac{\\text{RSS}}{n} $ and why do we divide RSS by the degrees of freedom for $ \\hat{\\sigma}^2 $?\n",
        "  - How does adjusting for degrees of freedom impact the estimate of the error variance?\n",
        "\n",
        "- How is the **covariance matrix** of the estimated coefficients $\\hat{\\beta} $ calculated?\n",
        "  - Write down the formula for the covariance matrix $ \\text{Cov}(\\hat{\\beta}) $.\n",
        "  - Why is it important to compute the **diagonal elements** of this matrix, and how do these relate to the standard errors of the coefficients?\n",
        "\n",
        "\n",
        "-  How is the t-test used to assess the statistical significance of the coefficients in linear regression?\n",
        "  - What is the null hypothesis in the t-test for a regression coefficient?\n",
        "  - How is the **t-value** calculated, and how do we use it to obtain the **p-value**?\n",
        "  - What is the relationship between the t-value, standard error of $ \\hat{\\beta}$, and the confidence intervals for the parameter?\n",
        "\n",
        "-  If a parameter's t-test returns a high p-value, what does that suggest about the significance of the parameter in the model?\n",
        "  - Should this parameter be kept or removed from the model, and why?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sa6IxK2v43Ys"
      },
      "outputs": [],
      "source": [
        "# Compute residuals\n",
        "residuals = model.fit().resid\n",
        "\n",
        "# Compute and print statistics\n",
        "print(\"Mean of residuals:\", residuals.mean())\n",
        "print(\"Standard deviation of residuals:\", residuals.std())\n",
        "print(\"Mean Squared Error (MSE):\", (residuals**2).sum()/len(cars))\n",
        "print(\"Variance of residuals:\", residuals.var())\n",
        "print(\"Scaled deviance of residuals:\", (residuals**2).sum() / (len(cars) - 2))\n",
        "print(\"Skewness of residuals:\", residuals.skew())\n",
        "print(\"Kurtosis of residuals:\", residuals.kurtosis())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-D9C4ffMMaU"
      },
      "outputs": [],
      "source": [
        "# compute mse of residuals\n",
        "mse1 = np.mean(residuals**2)\n",
        "print(\"Mean Squared Error (MSE) computed directly:\", mse1)\n",
        "mse2 = (residuals**2).sum()/len(cars)\n",
        "print(\"Mean Squared Error (MSE) computed from residuals:\", mse2)\n",
        "resid_mse= model.fit().mse_resid\n",
        "print(\"Mean Squared Error (MSE) from model fit:\", resid_mse)\n",
        "resid_mse2 = (residuals**2).sum()/(len(cars)-2)\n",
        "print(\"Mean Squared Error (MSE) from residuals (adjusted):\", resid_mse2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmwBMYHC-Oiq"
      },
      "outputs": [],
      "source": [
        "# Plot residuals as a histogram\n",
        "plt.hist(residuals, bins=20, edgecolor='k', alpha=0.65)\n",
        "plt.title('Histogram of Residuals')\n",
        "plt.xlabel('Residual')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Q-Q plot of residuals\n",
        "stats.probplot(residuals, plot=plt)\n",
        "plt.title('Q-Q Plot of Residuals')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ph-MENLv8gao"
      },
      "outputs": [],
      "source": [
        "# Plotting results\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "fig = sm.graphics.plot_fit(model.fit(), 1, ax=ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuVNFfCfvB3m"
      },
      "outputs": [],
      "source": [
        "def get_regression(X, Y):\n",
        "    \"\"\"\n",
        "    Calculate linear regression coefficients, standard errors,\n",
        "    t-values, p-values, and 95% confidence intervals.\n",
        "\n",
        "    Parameters:\n",
        "    - X: DataFrame or array-like of independent variables.\n",
        "    - Y: Series or array-like of dependent variable.\n",
        "\n",
        "    Returns:\n",
        "    - DataFrame with coefficients, standard errors, t-values, p-values,\n",
        "      and 95% confidence intervals.\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure X and Y are DataFrames or numpy arrays\n",
        "    X = pd.DataFrame(X.copy())  # X must be a DataFrame\n",
        "    Y = np.array(Y)  # Convert Y to NumPy array if it's a Series\n",
        "\n",
        "    # Add constant (intercept) term to X matrix\n",
        "    X['const'] = 1  # Adds intercept term\n",
        "    X = X[['const'] + [col for col in X if col != 'const']]  # Ensure 'const' is the first column\n",
        "\n",
        "    # Calculate regression coefficients (beta_hat) using the formula: (X'X)^(-1) X'Y\n",
        "    # Not efficient but simple\n",
        "    beta_hat = np.linalg.inv(X.values.T @ X.values) @ X.values.T @ Y\n",
        "\n",
        "    # Predicted values and residuals\n",
        "    Y_pred = X.values @ beta_hat  # Predicted Y\n",
        "    residuals = Y - Y_pred  # Residuals (actual Y - predicted Y)\n",
        "\n",
        "    # Residual Sum of Squares (RSS) = Sum of Sqeuares Errors (SSE)\n",
        "    RSS = residuals.T @ residuals\n",
        "\n",
        "    # Mean Squared Error (MSE)\n",
        "    MSE = RSS / Y.shape[0]\n",
        "\n",
        "    # Adjusted degrees of freedom (n - p), where n is the number of observations and p is the number of predictors\n",
        "    df = Y.shape[0] - X.shape[1]\n",
        "    # Unbiased estimate of the variance of the residuals (RSS divided by degrees of freedom)\n",
        "    sigma2_hat = RSS / df\n",
        "\n",
        "    # Standard errors of coefficients (sqrt of diagonal of covariance matrix)\n",
        "    se_beta_hat = np.sqrt(sigma2_hat * np.diag(np.linalg.inv(X.values.T @ X.values)))\n",
        "\n",
        "    # t-values and p-values\n",
        "    t_values = beta_hat / se_beta_hat\n",
        "    p_values = 2 * (1 - t.cdf(np.abs(t_values), df))\n",
        "\n",
        "    # Critical t-value for 95% confidence intervals\n",
        "    alpha = 0.05\n",
        "    t_critical = t.ppf(1 - alpha/2, df)\n",
        "\n",
        "    # 95% Confidence Intervals\n",
        "    ci_lower = beta_hat - t_critical * se_beta_hat\n",
        "    ci_upper = beta_hat + t_critical * se_beta_hat\n",
        "\n",
        "    # Create a DataFrame for the output\n",
        "    return pd.DataFrame({\n",
        "        'coef': beta_hat,\n",
        "        'std err': se_beta_hat,\n",
        "        't': t_values,\n",
        "        'P > |t|': p_values,\n",
        "        '95% CI Lower': ci_lower,\n",
        "        '95% CI Upper': ci_upper\n",
        "    }, index=X.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxIivnoW41mH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFsT0tq5vHcm"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Independent variable (X) - weight\n",
        "X = cars[['weight']]\n",
        "# Dependent variable (Y) - mpg\n",
        "Y = cars['mpg']\n",
        "\n",
        "# Compare manual OLS implementation with statsmodels\n",
        "manual_ols = get_regression(X, Y)\n",
        "print('Manual OLS Results:')\n",
        "print(manual_ols)\n",
        "\n",
        "X_with_const = sm.add_constant(X[['weight']])\n",
        "model = sm.OLS(Y, X_with_const)\n",
        "results = model.fit()\n",
        "print('Statsmodels OLS Results:')\n",
        "print(results.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzk-erYpKuxw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a829035"
      },
      "source": [
        "\n",
        "## Simple linear regression recap\n",
        "We first revisit the single-regressor case (MPG on weight) using a hand-crafted OLS routine and `statsmodels` for validation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls8mIR2XK0Zf"
      },
      "source": [
        "**Task:** In the simple linear regression model, construct a Wald test for $H_0 : \\beta_1 = 17 \\beta_0$ versus $H_1 : \\beta_1 \\neq 17 \\beta_0$.\n",
        "\n",
        "**Solution**.  Let $\\delta = \\beta_1 - 17 \\beta_0$.  The MLE is $\\hat{\\delta} = \\hat{\\beta}_1 - 17 \\hat{\\beta}_0$, with estimated standard error $\\hat{\\text{se}}(\\hat{\\delta})$, where\n",
        "\n",
        "$$\\hat{\\text{se}}(\\hat{\\delta})^2 = \\hat{\\text{se}}(\\hat{\\beta}_1 - 17 \\hat{\\beta}_0)^2 = \\hat{\\text{se}}(\\hat{\\beta}_1)^2 + 17^2 \\hat{\\text{se}}(\\hat{\\beta}_0)^2 $$\n",
        "\n",
        "\n",
        "The Wald test then checks if $|W| < z_{\\alpha / 2}$, where\n",
        "\n",
        "$$W = \\frac{\\hat{\\delta} - 0}{\\hat{\\text{se}}(\\hat{\\delta})}\n",
        "= \\frac{\\hat{\\beta}_1 - 17 \\hat{\\beta}_0}{\\sqrt{\\hat{\\text{se}}(\\hat{\\beta}_1)^2 + 17^2 \\hat{\\text{se}}(\\hat{\\beta}_0)^2}}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SqWwZB0Nhxt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cade49ae"
      },
      "source": [
        "\n",
        "### Model comparison via F-test\n",
        "We compare an intercept-only baseline against the weight model using the classic nested-model F-test.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0gIld6NDaHo"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import f\n",
        "\n",
        "# Fit the two models\n",
        "fit0 = smf.ols('mpg ~ 1', data=cars).fit()  # Restricted model mpg ~ 1 (intercept only)\n",
        "fit1 = smf.ols('mpg ~ weight', data=cars).fit() # Full model mpg ~ weight\n",
        "\n",
        "# Get RSS for both models\n",
        "RSS0 = np.sum(fit0.resid ** 2)  # Residual sum of squares for restricted model\n",
        "RSS1 = np.sum(fit1.resid ** 2)  # Residual sum of squares for full model\n",
        "\n",
        "# Number of observations and number of parameters\n",
        "n = len(cars)\n",
        "p0 = 1  # Number of parameters in the restricted model (intercept)\n",
        "p1 = 2  # Number of parameters in the full model (intercept + weight)\n",
        "\n",
        "# Degrees of freedom for both models\n",
        "df0 = n - p0  # Degrees of freedom for fit0\n",
        "df1 = n - p1  # Degrees of freedom for fit1\n",
        "\n",
        "# Compute the F-statistic\n",
        "numerator = (RSS0 - RSS1) / (p1 - p0)  # Improvement in RSS\n",
        "denominator = RSS1 / df1  # Error in the full model\n",
        "\n",
        "F_stat = numerator / denominator\n",
        "print(f\"F-statistic: {F_stat}\")\n",
        "\n",
        "# Compare with critical value from F-distribution\n",
        "alpha = 0.05  # Significance level\n",
        "F_critical = f.ppf(1 - alpha, p1 - p0, df1)\n",
        "print(f\"Critical F-value at 5% significance: {F_critical}\")\n",
        "\n",
        "# p-value from the F-distribution\n",
        "p_value = 1 - f.cdf(F_stat, p1 - p0, df1)\n",
        "print(f\"P-value: {p_value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xc9nSLG3GIXT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compare R-squared definitions for models with and without intercepts\n",
        "fit1 = smf.ols('mpg ~ weight', data=cars).fit()\n",
        "fit2 = smf.ols('mpg ~ -1 + weight', data=cars).fit()\n",
        "\n",
        "RSS1 = np.sum(fit1.resid ** 2)\n",
        "RSS2 = np.sum(fit2.resid ** 2)\n",
        "\n",
        "TSS_with_intercept = np.sum((cars['mpg'] - cars['mpg'].mean()) ** 2)\n",
        "TSS_no_intercept = np.sum(cars['mpg'] ** 2)\n",
        "\n",
        "R2_1_manual = 1 - (RSS1 / TSS_with_intercept)\n",
        "R2_2_manual = 1 - (RSS2 / TSS_no_intercept)\n",
        "\n",
        "R2_1_sm = fit1.rsquared\n",
        "R2_2_sm = fit2.rsquared\n",
        "\n",
        "print(f'Manual R-squared for fit1 (with intercept): {R2_1_manual}')\n",
        "print(f'Manual R-squared for fit2 (without intercept): {R2_2_manual}')\n",
        "\n",
        "print(f'R-squared from statsmodels for fit1 (with intercept): {R2_1_sm}')\n",
        "print(f'R-squared from statsmodels for fit2 (without intercept): {R2_2_sm}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AO7tajXnHI-7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Demonstrate the pitfall of using the centered TSS with a no-intercept model\n",
        "TSS_wrong = np.sum((cars['mpg'] - cars['mpg'].mean()) ** 2)\n",
        "R2_wrong = 1 - (RSS2 / TSS_wrong)\n",
        "print(f'Wrong R-squared for fit2 (using intercept-based formula): {R2_wrong}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8OdLKKkHY5K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8r_MtfWm-Oln"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDh806z0-Oou"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de8f25e7"
      },
      "source": [
        "\n",
        "## Multiple regression extension\n",
        "We add regional information to the weight regressor and compare manual vs. library-based OLS fits.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jM-xAY09vCsu"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Build design matrix with weight and origin dummies\n",
        "X = cars[['weight', 'origin']]\n",
        "X = pd.get_dummies(X, drop_first=True).astype(float)\n",
        "Y = cars['mpg']\n",
        "\n",
        "manual_ols = get_regression(X, Y)\n",
        "print('Manual OLS Results:')\n",
        "print(manual_ols)\n",
        "\n",
        "X_with_const = sm.add_constant(X)\n",
        "model = sm.OLS(Y, X_with_const)\n",
        "results = model.fit()\n",
        "print('Statsmodels OLS Results:')\n",
        "print(results.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9GbHZE4wTeI"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Equivalent fit using the formula interface\n",
        "model = smf.ols('mpg ~ weight + origin', data=cars)\n",
        "results = model.fit()\n",
        "print('Statsmodels OLS Results:')\n",
        "print(results.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5L2sCkBVwUIp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rB-1Z9KhwUMG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTBmD5puuruu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOK9NucwoTKb"
      },
      "outputs": [],
      "source": [
        "# Linear Regression for different countries\n",
        "countries = cars['origin'].unique()\n",
        "\n",
        "for country in countries:\n",
        "    country_data = cars[cars['origin'] == country]\n",
        "    model_country = smf.ols('mpg ~ horsepower', data=country_data).fit()\n",
        "    print(f'Regression for Country: {country}')\n",
        "    print(model_country.summary())\n",
        "\n",
        "    # Plot for each country\n",
        "    plt.figure()\n",
        "    sns.regplot(x='horsepower', y='mpg', data=country_data, ci=None, line_kws={\"color\": \"red\"})\n",
        "    plt.title(f'MPG vs Horsepower - {country}')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-uCvbZInv_y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N42l2emMnwCm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7eb7d16"
      },
      "source": [
        "\n",
        "## Key takeaways\n",
        "- Group comparisons (t-tests, ANOVA, Tukey) reveal how fuel efficiency varies by origin before modelling.\n",
        "- Manual OLS derivations mirror library output and highlight the impact of including an intercept.\n",
        "- Extending to multiple regression requires careful handling of categorical predictors via dummy coding.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TSyBV0DJtFd"
      },
      "source": [
        "# Student Individual Work\n",
        "\n",
        "### 1. Convert `mpg` to liters per 100 km\n",
        "- **Task**: Convert the fuel consumption in `mpg` (miles per gallon) to liters per 100 kilometers (L/100km).\n",
        "- **Formula**:\n",
        "  $\n",
        "  \\text{L/100km} = \\frac{235.215}{\\text{mpg}}\n",
        "  $\n",
        "- **Question**: What is the average fuel consumption in liters per 100 km for the dataset?\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Convert `horsepower` to kilowatts (kW)\n",
        "- **Task**: Convert the engine power from `horsepower (hp)` to `kilowatts (kW)`.\n",
        "- **Formula**:\n",
        "  $\n",
        "  \\text{kW} = \\text{hp} \\times 0.7355\n",
        "  $\n",
        "- **Question**: What is the range of engine power in kilowatts for the dataset?\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Run regression analysis on how `liters_per_100km` depends on `kw` (engine power)\n",
        "- **Task**: Perform regression analysis to understand the relationship between fuel consumption (`liters_per_100km`) and engine power (`kw`).\n",
        "- **Question**: What are the coefficients of the regression model? How do they interpret the relationship between fuel consumption and engine power?\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Run the same regression analysis using a model **with and without intercept**\n",
        "- **Task**: Run two regression models-one with an intercept and one without an intercept.\n",
        "- **Question**: How do the models differ? What are the key differences in the interpretation of the results between the two models?\n",
        "\n",
        "---\n",
        "\n",
        "### 5. Discuss the F-statistic and R-squared for both models\n",
        "- **Task**: Compare the F-statistic and R-squared for both models (with and without intercept).\n",
        "- **Question**: Which model better explains the data, and why? Which one would you choose and under what circumstances?\n",
        "\n",
        "---\n",
        "\n",
        "### 6. Test if the regression coefficient for the Intercept is equal to 10 times the regression coefficient for engine power\n",
        "- **Task**: Test the hypothesis that the intercept is equal to 10 times the regression coefficient for engine power.\n",
        "  $\n",
        "  H_0: \\beta_0 = 10 \\times \\beta_1 \\quad vs. \\quad H_1: \\beta_0 \\neq 10 \\times \\beta_1\n",
        "  $\n",
        "- **Question**: Can we reject the null hypothesis? What does this tell us about the relationship between the intercept and engine power?\n",
        "\n",
        "---\n",
        "\n",
        "### 7. Compare fuel consumption for cars from Europe and Japan\n",
        "- **Task**: Compare the fuel consumption (in liters per 100 km) between European and Japanese cars at different engine power levels (kW).\n",
        "- **Question**: For what engine power (`kw`) do European cars have smaller fuel consumption than Japanese cars?\n",
        "\n",
        "---\n",
        "\n",
        "### 8. Investigate the impact of `weight` on fuel consumption\n",
        "- **Task**: Add `weight` as a second predictor in the regression model to see how it affects the relationship between engine power and fuel consumption.\n",
        "- **Question**: Does `weight` significantly improve the model? How does it affect the coefficients and interpretation of `kw`?\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### 9. Predict the fuel consumption of a car with 150 kW engine power and discuss the prediction interval\n",
        "- **Task**: Use the regression model to predict the fuel consumption of a car with 150 kW engine power (for each origin).\n",
        "- **Question**: What is the predicted fuel consumption? How confident are we in this prediction?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9EC2HO8nxNs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LUEH3IbnxQQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIbGzK9NnxS3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaDYtnGNnxVT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPUPEgVHlQ8U"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}