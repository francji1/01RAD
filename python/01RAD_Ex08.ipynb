{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMMAFhypk2Z7g2OtU8qPz7C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francji1/01RAD/blob/main/python/01RAD_Ex08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 08"
      ],
      "metadata": {
        "id": "IySLvMRC2IO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets use the same dataset from the last exercise"
      ],
      "metadata": {
        "id": "-QNdlNCjnxsf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "binLmBw41zGH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "from itertools import combinations\n",
        "from statsmodels.formula.api import ols\n",
        "from scipy.stats import f,t,norm"
      ],
      "metadata": {
        "id": "kcuAltnr13Nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cars_all = pd.read_csv(\"https://raw.githubusercontent.com/francji1/01RAD/main/data/carsdata2.csv\", sep=\";\")\n",
        "cars_all.head()"
      ],
      "metadata": {
        "id": "IXlL6QzQ13RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cars_all"
      ],
      "metadata": {
        "id": "b4imaZUj3zXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cars_all.isna().sum()\n"
      ],
      "metadata": {
        "id": "yaZfc6n213Tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define car types and wheel drive conditions\n",
        "sedan_condition = cars_all['Sedan'] == 1\n",
        "sport_condition = cars_all['Sports'] == 1\n",
        "suv_condition = cars_all['SUV'] == 1\n",
        "minivan_condition = (cars_all['Wagon'] == 1) | (cars_all['Minivan'] == 1) | (cars_all['Pickup'] == 1)\n",
        "awd_condition = cars_all['AWD'] == 1\n",
        "rwd_condition = cars_all['RWD'] == 1\n",
        "\n",
        "cars_all = (\n",
        "    cars_all.assign(\n",
        "        consumption=100 / (1.60934 * ((cars_all['CityMPG'] + cars_all['HwyMPG']) / 2) / 3.7854),\n",
        "        type=np.select(\n",
        "            [sedan_condition, sport_condition, suv_condition, minivan_condition],\n",
        "            ['sedan', 'sport', 'suv', 'minivan'],\n",
        "            default='Unknown'\n",
        "        ),\n",
        "        wheel_drive=np.select(\n",
        "            [awd_condition, rwd_condition],\n",
        "            ['AWD', 'RWD'],\n",
        "            default='FWD'\n",
        "        )\n",
        "    )\n",
        "    .astype({'type': 'category', 'wheel_drive': 'category'})\n",
        "    .filter(['RetailPrice', 'type', 'consumption', 'wheel_drive', 'DealerCost', 'EngineSize', 'Cyl', 'HP', 'Weight', 'WheelBase', 'Len', 'Width'])\n",
        ")\n",
        "\n",
        "cars_all.head()"
      ],
      "metadata": {
        "id": "FvIEAmX846v0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "txrPJP__39t4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Omit rows with NA values\n",
        "cars_all.dropna(inplace=True)\n",
        "cars_all.isna().sum()\n"
      ],
      "metadata": {
        "id": "D3DUeTPiisAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cars = cars_all.drop(columns = ['Cyl','DealerCost']).copy()"
      ],
      "metadata": {
        "id": "c9nQmsbr0fbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cars"
      ],
      "metadata": {
        "id": "rIphI_T50ixj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cars.to_csv('cars.csv', index=False)\n"
      ],
      "metadata": {
        "id": "pDwEi8460i1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show how to handle with formula with/without one hot encoded varialbes."
      ],
      "metadata": {
        "id": "ReM8Cn11p4a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encoding for categorical variables\n",
        "cars_data_encoded = pd.get_dummies(cars, columns=['type', 'wheel_drive'], drop_first=True)\n",
        "\n",
        "# Building the full model with all predictors and their second-order interactions\n",
        "# First, prepare the formula for the full model\n",
        "predictors = cars_data_encoded.columns.drop('Weight')\n",
        "interaction_terms = ['{}:{}'.format(a, b) for a, b in combinations(predictors, 2)]\n",
        "formula_full = 'Weight ~ ' + ' + '.join(predictors) + ' + ' + ' + '.join(interaction_terms) + '-' +  'type_sport:type_suv'\n",
        "# not work: formula_full = 'Weight ~ (.)^2 ' , * works\n",
        "formula_full"
      ],
      "metadata": {
        "id": "pL_6O_Mz0vnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the full model\n",
        "full_model = smf.ols(formula=formula_full, data=cars_data_encoded).fit()\n",
        "\n",
        "# Display the summary of the full model\n",
        "full_model_summary = full_model.summary()\n",
        "full_model_aic = full_model.aic\n",
        "full_model_bic = full_model.bic\n",
        "\n",
        "print(full_model_summary)"
      ],
      "metadata": {
        "id": "3UrQiDlwoTtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "\n",
        "# Function for fitting a model and getting AIC and BIC\n",
        "def fit_model(formula, data):\n",
        "    model = smf.ols(formula, data=data).fit()\n",
        "    return model.aic, model.bic, model\n",
        "\n",
        "# Stepwise Regression\n",
        "def stepwise_selection(data, response, initial_list=[], threshold_in=0.01, threshold_out=0.05):\n",
        "    included = list(initial_list)\n",
        "    while True:\n",
        "        changed = False\n",
        "\n",
        "        # Forward step\n",
        "        excluded = list(set(data.columns) - set(included) - {response})\n",
        "        new_pval = pd.Series(index=excluded, dtype=float)\n",
        "        for new_column in excluded:\n",
        "            model = smf.ols(f'{response} ~ ' + ' + '.join(included + [new_column]), data=data).fit()\n",
        "            new_pval[new_column] = model.pvalues[new_column]\n",
        "        best_pval = new_pval.min()\n",
        "        if best_pval < threshold_in:\n",
        "            best_feature = new_pval.idxmin()\n",
        "            included.append(best_feature)\n",
        "            changed = True\n",
        "\n",
        "        # Backward step\n",
        "        model = smf.ols(f'{response} ~ ' + ' + '.join(included), data=data).fit()\n",
        "        # Use all coefs except intercept\n",
        "        pvalues = model.pvalues.iloc[1:]\n",
        "        worst_pval = pvalues.max()  # null if pvalues is empty\n",
        "        if worst_pval > threshold_out:\n",
        "            changed = True\n",
        "            worst_feature = pvalues.idxmax()\n",
        "            included.remove(worst_feature)\n",
        "\n",
        "        if not changed:\n",
        "            break\n",
        "\n",
        "    return included\n",
        "\n",
        "# Run stepwise selection\n",
        "predictors_stepwise = stepwise_selection(cars_data_encoded, 'Weight')\n",
        "\n",
        "# Fit the model with selected predictors\n",
        "formula_stepwise = 'Weight ~ ' + ' + '.join(predictors_stepwise)\n",
        "aic_stepwise, bic_stepwise, reduced_model = fit_model(formula_stepwise, cars_data_encoded)\n",
        "\n",
        "predictors_stepwise, aic_stepwise, bic_stepwise, formula_stepwise\n"
      ],
      "metadata": {
        "id": "zDfTBLmEBjry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reduced_model.summary())"
      ],
      "metadata": {
        "id": "LfW_rX8hEUwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conduct ANOVA (F-test) to compare the full model and the reduced model\n",
        "anova_results = anova_lm(reduced_model, full_model)\n",
        "anova_results\n"
      ],
      "metadata": {
        "id": "fRrgFY6nBa0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Component-Residual Plot (Partial Residual Plots):\n",
        "\n",
        "* What to See: These plots show the relationship between each predictor and the response variable while controlling for the effect of other variables. They are useful for checking linearity and identifying outliers or influential points.\n",
        "* Why to Plot: To verify the assumption that the relationship between predictors and the response is linear, and to spot any non-linear patterns, outliers, or points that might have a disproportionate impact on the regression model.\n",
        "\n",
        "###Added Variable Plot (Partial Regression Plots):\n",
        "\n",
        "* What to See: These plots display the relationship between the response and a given predictor, after removing the effect of all other predictors. They help in understanding the individual contribution of a predictor to the model.\n",
        "* Why to Plot: To assess the unique impact of each predictor on the response, checking for linearity, and identifying potential outliers or influential observations that might affect the slope of the regression line.\n",
        "\n",
        "### Spread-Level Plot:\n",
        "\n",
        "* What to See: This plot shows the spread or variance of the residuals against the predicted values or a predictor. It's used to check the assumption of homoscedasticity (constant variance of errors).\n",
        "* Why to Plot: To ensure that the error variance is constant across all levels of the predictors. Non-constant variance (heteroscedasticity) can indicate that the model is not capturing some aspect of the data, possibly violating regression assumptions."
      ],
      "metadata": {
        "id": "P0fIkcOWq2JS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from statsmodels.graphics.regressionplots import plot_partregress_grid, plot_ccpr_grid\n",
        "\n",
        "# Component-Residual Plot (Partial Residual Plots)\n",
        "plot_ccpr_grid(reduced_model)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Added Variable Plot (Partial Regression Plots)\n",
        "fig = plt.figure(figsize=(16, 12))\n",
        "plot_partregress_grid(reduced_model, fig=fig)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Spread-Level Plot (Residuals vs Predicted)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(x=reduced_model.fittedvalues, y=reduced_model.resid)\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Spread-Level Plot')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rMA5MNX7Ba3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.graphics.regressionplots import plot_regress_exog\n",
        "\n",
        "# Check residuals against each independent variable using plot_regress_exog\n",
        "key_predictors = ['consumption', 'WheelBase', 'Width']\n",
        "\n",
        "for predictor in key_predictors:\n",
        "    fig = plt.figure(figsize=(14, 10))\n",
        "    plot_regress_exog(reduced_model, predictor, fig=fig)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "F-OKLGmjBa57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KzK7ACOqBa8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract predictors from the reduced model\n",
        "predictors_stepwise = reduced_model.model.exog_names\n",
        "predictors_stepwise.remove('Intercept')  # Remove the intercept from the list\n"
      ],
      "metadata": {
        "id": "yYDF1GRlBa_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cars"
      ],
      "metadata": {
        "id": "_c85J0cmKQYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictors_stepwise"
      ],
      "metadata": {
        "id": "VhmomGrSJtHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.formula.api as smf\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# One-hot encoding for categorical variables\n",
        "cars_data_encoded = pd.get_dummies(cars, columns=['type', 'wheel_drive'], drop_first=True)\n",
        "\n",
        "# Extract predictors from the reduced model\n",
        "predictors_stepwise = reduced_model.model.exog_names\n",
        "#predictors_stepwise.remove('Intercept')  # Remove the intercept from the list\n",
        "\n",
        "# Log Transformation of the Response\n",
        "cars_data_encoded['log_Weight'] = np.log(cars_data_encoded['Weight'])\n",
        "formula_log = 'log_Weight ~ ' + ' + '.join(predictors_stepwise)\n",
        "model_log = smf.ols(formula=formula_log, data=cars_data_encoded).fit()\n",
        "\n",
        "# Box-Cox Transformation of the Response\n",
        "box_cox_transformed, best_lambda = stats.boxcox(cars_data_encoded['Weight'])\n",
        "cars_data_encoded['box_cox_Weight'] = box_cox_transformed\n",
        "formula_box_cox = 'box_cox_Weight ~ ' + ' + '.join(predictors_stepwise)\n",
        "model_box_cox = smf.ols(formula=formula_box_cox, data=cars_data_encoded).fit()\n",
        "\n",
        "# Collecting summary statistics for comparison\n",
        "log_model_summary = model_log.summary()\n",
        "box_cox_model_summary = model_box_cox.summary()\n",
        "\n",
        "print(\"Best Lambda for Box-Cox Transformation:\", best_lambda)\n",
        "print(\"\\nLog-Transformed Model Summary:\\n\", log_model_summary)\n",
        "print(\"\\nBox-Cox Transformed Model Summary:\\n\", box_cox_model_summary)"
      ],
      "metadata": {
        "id": "BpG3AvxoIJF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "from matplotlib import gridspec\n",
        "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
        "\n",
        "# Using the 'Weight' variable from the cars_data_encoded dataframe\n",
        "x = cars_data_encoded['Weight']\n",
        "\n",
        "# Lambda range and corresponding log-likelihood values\n",
        "lmbdas = np.linspace(-2, 2, 400)\n",
        "llf = [stats.boxcox_llf(lmbda, x) for lmbda in lmbdas]\n",
        "\n",
        "# Finding the lambda that maximizes the log-likelihood\n",
        "lmbda_optimal = lmbdas[np.argmax(llf)]\n",
        "\n",
        "# Plotting the log-likelihood as a function of lambda\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "gs = gridspec.GridSpec(1, 1)\n",
        "ax = fig.add_subplot(gs[0])\n",
        "ax.plot(lmbdas, llf, 'b.-')\n",
        "ax.axhline(stats.boxcox_llf(lmbda_optimal, x), color='r')\n",
        "ax.set_xlabel('Lambda parameter')\n",
        "ax.set_ylabel('Box-Cox log-likelihood')\n",
        "\n",
        "# Inset plots for different lambda values\n",
        "locs = [3, 10, 4]  # 'lower left', 'center', 'lower right'\n",
        "for lmbda, loc in zip([-1, lmbda_optimal, 9], locs):\n",
        "    xt = stats.boxcox(x, lmbda=lmbda)\n",
        "    (osm, osr), (slope, intercept, r_sq) = stats.probplot(xt)\n",
        "    ax_inset = inset_axes(ax, width=\"20%\", height=\"20%\", loc=loc)\n",
        "    ax_inset.plot(osm, osr, 'c.', osm, slope*osm + intercept, 'k-')\n",
        "    ax_inset.set_xticklabels([])\n",
        "    ax_inset.set_yticklabels([])\n",
        "    ax_inset.set_title(r'$\\lambda=%1.2f$' % lmbda)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "lmbda_optimal\n"
      ],
      "metadata": {
        "id": "-9n9q0G6IJLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scipy box cox functions:\n",
        "* https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.boxcox.html\n",
        "* https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.boxcox_llf.html\n"
      ],
      "metadata": {
        "id": "Fn5M-myQfCqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recalculating the confidence interval for the optimal lambda using the correct method\n",
        "_, lmbda_optimal, (lmbda_ci_lower, lmbda_ci_upper) = stats.boxcox(x, alpha=0.05)\n",
        "\n",
        "# Replotting the log-likelihood as a function of lambda with the correct confidence interval\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "gs = gridspec.GridSpec(1, 1)\n",
        "ax = fig.add_subplot(gs[0])\n",
        "ax.plot(lmbdas, llf, 'b.-')\n",
        "ax.axhline(stats.boxcox_llf(lmbda_optimal, x), color='r')\n",
        "ax.axvline(lmbda_optimal, color='r', linestyle='--', label=f'Optimal Lambda: {lmbda_optimal:.2f}')\n",
        "ax.axvline(lmbda_ci_lower, color='g', linestyle='--', label=f'CI Lower: {lmbda_ci_lower:.2f}')\n",
        "ax.axvline(lmbda_ci_upper, color='g', linestyle='--', label=f'CI Upper: {lmbda_ci_upper:.2f}')\n",
        "ax.set_xlabel('Lambda parameter')\n",
        "ax.set_ylabel('Box-Cox log-likelihood')\n",
        "ax.legend()\n",
        "\n",
        "# Insert plots for different lambda values\n",
        "locs = [3, 10, 4]  # 'lower left', 'center', 'lower right'\n",
        "for lmbda, loc in zip([-1, lmbda_optimal, 9], locs):\n",
        "    xt = stats.boxcox(x, lmbda=lmbda)\n",
        "    (osm, osr), (slope, intercept, r_sq) = stats.probplot(xt)\n",
        "    ax_inset = inset_axes(ax, width=\"20%\", height=\"20%\", loc=loc)\n",
        "    ax_inset.plot(osm, osr, 'c.', osm, slope*osm + intercept, 'k-')\n",
        "    ax_inset.set_xticklabels([])\n",
        "    ax_inset.set_yticklabels([])\n",
        "    ax_inset.set_title(r'$\\lambda=%1.2f$' % lmbda)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "(lmbda_optimal, lmbda_ci_lower, lmbda_ci_upper)\n"
      ],
      "metadata": {
        "id": "W09sYX1WIJN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iRoBxFL9IJQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3MX-7OQXIJTp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}